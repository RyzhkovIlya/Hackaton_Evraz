{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "evraz.3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWpnJR2rAxth",
        "outputId": "c1a7559d-7098-4eec-d05f-35085468e2bc"
      },
      "source": [
        "!pip install flaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flaml\n",
            "  Downloading FLAML-0.6.9-py3-none-any.whl (157 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 33.3 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 20 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 30 kB 19.7 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 40 kB 17.2 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 51 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 61 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 71 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 81 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 92 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 102 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 112 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 122 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 133 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 143 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 153 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 157 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from flaml) (0.24.0)\n",
            "Requirement already satisfied: xgboost<=1.3.3,>=0.90 in /usr/local/lib/python3.7/dist-packages (from flaml) (0.90)\n",
            "Requirement already satisfied: NumPy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.19.5)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.1.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.4.1)\n",
            "Collecting lightgbm>=2.3.1\n",
            "  Downloading lightgbm-3.3.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 55.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->flaml) (0.37.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->flaml) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->flaml) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.4->flaml) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml) (1.0.1)\n",
            "Installing collected packages: lightgbm, flaml\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed flaml-0.6.9 lightgbm-3.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "eIVlnlN_BzwQ",
        "outputId": "ada1bca3-68e2-4c88-b914-78092e46f4ed"
      },
      "source": [
        "!pip install scikit-learn==0.24"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==0.24\n",
            "  Downloading scikit_learn-0.24.0-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 59.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.4.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.24.0 threadpoolctl-3.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6rx0uSMD9BK",
        "outputId": "897cde3d-d969-4f62-db0f-52b133604ace"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.0.1-cp37-none-manylinux1_x86_64.whl (76.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.3 MB 29 kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp7wGzP7z5Or",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8856c058-79df-480a-a589-ee0f9f35085f"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "import flaml\n",
        "from flaml import AutoML\n",
        "from flaml.ml import sklearn_metric_loss_score\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import norm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_absolute_error"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLE1BtCmRbIq"
      },
      "source": [
        "def laben(df,feat):\n",
        "    \"\"\"\n",
        "    Функция проводит LabelEncodind и преобразует признак в категориальный\n",
        "    \"\"\"\n",
        "    labenc = LabelEncoder()\n",
        "    df[feat] = labenc.fit_transform(df[feat])\n",
        "    df[feat] = df[feat].astype('category')\n",
        "    return df[feat]\n",
        "\n",
        "def datet(df, feat):\n",
        "    \"\"\"\n",
        "    Функция преобазует признак в ттип datetime64[s]\n",
        "    \"\"\"\n",
        "    df[feat] = df[feat].astype('datetime64[s]')\n",
        "    return df[feat]\n",
        "\n",
        "def ekran_chronom(df):\n",
        "    \"\"\"\n",
        "    Функция преобразует таблицу chronom\n",
        "    \"\"\"\n",
        "    feat = df.NPLV.unique()\n",
        "    df_1 = pd.DataFrame(columns=['NPLV','TYPE_OPER','VR', 'O2'])\n",
        "    for i in feat:\n",
        "        df_2 = df[df['NPLV']==i].sort_values(by='VR_NACH')\n",
        "        lst = []\n",
        "        for j in df_2.index:\n",
        "            lst.append(str(df_2.TYPE_OPER.loc[j]))\n",
        "        df_1.loc[len(df_1)] = [i,','.join(sorted(set(lst))), int(pd.Timedelta(df_2.VR_KON.iloc[-1] - df_2.VR_NACH.iloc[0]).seconds), int(df_2.O2.sum())]\n",
        "    return df_1\n",
        "\n",
        "def ekran_lom(df):\n",
        "    \"\"\"\n",
        "    Функция преобразует таблицу lom\n",
        "    \"\"\"\n",
        "    feat = df.NPLV.unique()\n",
        "    df_1 = pd.DataFrame(columns=['NPLV','VDL','VES'])\n",
        "    for i in feat:\n",
        "        df_2 = df[df['NPLV']==i]\n",
        "        lst = []\n",
        "        ves_sum = 0\n",
        "        for j in df_2.index:\n",
        "            lst.append(str(df_2.VDL.loc[j]))\n",
        "            ves_sum += df.VES.loc[j]\n",
        "        df_1.loc[len(df_1)] = [i, ','.join(sorted(set(lst))), int(ves_sum)]\n",
        "    return df_1\n",
        "\n",
        "def ekran_plavki(df):\n",
        "    \"\"\"\n",
        "    Функция преобразует таблицу plavki\n",
        "    \"\"\"\n",
        "    feat = df.NPLV.unique()\n",
        "    num = [i for i in feat if df.NPLV.to_list().count(i)>1]\n",
        "    return num\n",
        "\n",
        "def ekran_produv(df):\n",
        "    \"\"\"\n",
        "    Функция преобразует таблицу produv\n",
        "    \"\"\"\n",
        "    feat = df.NPLV.unique()\n",
        "    df_1 = pd.DataFrame(columns=['NPLV','RAS','POL'])\n",
        "    for i in feat:\n",
        "        df_2 = df[df['NPLV']==i]\n",
        "        ras_list = []\n",
        "        pol_list = []\n",
        "        for j in df_2.index:\n",
        "            ras_list.append(df_2.RAS.loc[j])\n",
        "            pol_list.append(df_2.POL.loc[j])\n",
        "        df_1.loc[len(df_1)] = [i, float(max(ras_list)), float(np.mean(pol_list))]\n",
        "    return df_1\n",
        "\n",
        "def ekran_sip(df):\n",
        "    \"\"\"\n",
        "    Функция преобразует таблицу sip\n",
        "    \"\"\"\n",
        "    feat = df.NPLV.unique()\n",
        "    df_1 = pd.DataFrame(columns=['NPLV','VDSYP','VSSYP', 'DAT_OTD'])\n",
        "    for i in feat:\n",
        "        df_2 = df[df['NPLV']==i].sort_values(by='DAT_OTD')\n",
        "        lst = []\n",
        "        ves_sum = 0\n",
        "        for j in df_2.index:\n",
        "            lst.append(str(df_2.VDSYP.loc[j]))\n",
        "            ves_sum += df_2.VSSYP.loc[j]\n",
        "        df_1.loc[len(df_1)] = [i, ','.join(sorted(set(lst))), int(ves_sum), int(pd.Timedelta(df_2.DAT_OTD.iloc[-1] - df_2.DAT_OTD.iloc[0]).seconds)]\n",
        "    return df_1\n",
        "\n",
        "def concat(train_data, test_data):\n",
        "    '''Функция соединяет несколько датасетов в один'''\n",
        "    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n",
        "\n",
        "def separate(all_data):\n",
        "    \"\"\"\n",
        "    Функция разделяет датасет на train и valid\n",
        "    \"\"\"\n",
        "    return all_data.loc[:2058], all_data.loc[2059:]\n",
        "\n",
        "def OneHotEncoding(df): # не используем\n",
        "    \"\"\"\n",
        "    Функция производит OneHotEncoding\n",
        "    \"\"\"\n",
        "    dd = df.select_dtypes(include='category').columns\n",
        "    if len(dd)>1:\n",
        "        for i in dd:\n",
        "            df = pd.concat([df, pd.get_dummies(df[i], prefix=(i+'M'))], axis=1)\n",
        "            df.drop(i, axis=1, inplace=True)\n",
        "        return df\n",
        "    if len(dd)==1:\n",
        "        df = pd.concat([df, pd.get_dummies(df[dd], prefix=(dd+'M'))], axis=1)\n",
        "        df.drop(dd, axis=1, inplace=True)\n",
        "        return df\n",
        "    else:\n",
        "        print(False)\n",
        "\n",
        "def metric(answers, user_csv):\n",
        "    \"\"\"\n",
        "    Функция метрики\n",
        "    \"\"\"\n",
        "    delta_c = np.abs(np.array(answers['C']) - np.array(user_csv['C']))\n",
        "    hit_rate_c = np.int64(delta_c < 0.02)\n",
        "    delta_t = np.abs(np.array(answers['TST']) - np.array(user_csv['TST']))\n",
        "    hit_rate_t = np.int64(delta_t < 20)\n",
        "    N = np.size(answers['C'])\n",
        "    return np.sum(hit_rate_c + hit_rate_t) / 2 / N"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUUc0Rbn2MlL"
      },
      "source": [
        "chronom_test = pd.read_csv('/content/drive/MyDrive/Evraz/task1/task1/data_task1/data_task1/chronom_test.csv')\n",
        "chronom_train = pd.read_csv('/content/drive/MyDrive/Evraz/task1/task1/data_task1/data_task1/chronom_train.csv')\n",
        "# NPLV\tномер плавки\n",
        "# TYPE_OPER\tтип операции\n",
        "# NOP\tнаименование операции\n",
        "# VR_NACH\tвремя начала операции\n",
        "# VR_KON\tвремя окончания операции\n",
        "# O2\tколичество кислорода, израсходованное на операцию"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HYQ8S0v0LNw"
      },
      "source": [
        "chronom_all = concat(chronom_train, chronom_test)\n",
        "chronom_all.drop('Unnamed: 0', axis = 1 , inplace=True)\n",
        "list_feat = ['VR_NACH','VR_KON']\n",
        "for i in list_feat:\n",
        "    chronom_all[i] = datet(chronom_all, i)\n",
        "chronom_all = chronom_all.dropna(subset=['VR_KON'])\n",
        "chronom_all = chronom_all.drop(chronom_all[chronom_all['VR_NACH'] < '2021'].index)\n",
        "chronom_all = ekran_chronom(chronom_all)\n",
        "chronom_all.drop(chronom_all[chronom_all.NPLV == 512233].index, inplace=True)\n",
        "chronom_all.drop(chronom_all[chronom_all.NPLV == 511135].index, inplace=True)\n",
        "chronom_all.drop(chronom_all[chronom_all.NPLV == 511156].index, inplace=True)\n",
        "chronom_all.drop(chronom_all[chronom_all.NPLV == 512299].index, inplace=True)\n",
        "chronom_all.NPLV = chronom_all.NPLV.astype('int64')\n",
        "chronom_all.O2 = chronom_all.O2.astype('int64')\n",
        "chronom_all.reset_index(drop=True, inplace=True)\n",
        "chronom_train_new, chronom_test_new = separate(chronom_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8lgpOE82b9Y"
      },
      "source": [
        "chugun_test = pd.read_csv('/content/drive/MyDrive/Evraz/task1/task1/data_task1/data_task1/chugun_test.csv')\n",
        "chugun_test.drop('DATA_ZAMERA', 1, inplace=True)\n",
        "chugun_test.reset_index(drop=True, inplace=True)\n",
        "chugun_train = pd.read_csv('/content/drive/MyDrive/Evraz/task1/task1/data_task1/data_task1/chugun_train.csv')\n",
        "chugun_train.drop('DATA_ZAMERA', 1, inplace=True)\n",
        "# NPLV\tномер плавки\n",
        "# VES\tвес чугуна\n",
        "# T\tтемпература чугуна\n",
        "# SI\tSI вчугуне\n",
        "# MN\tMN в чугуне\n",
        "# S\tS в чугуне\n",
        "# P\tP в чугуне\n",
        "# CR\tCR в чугуне\n",
        "# NI\tNI в чугуне\n",
        "# CU\tCU в чугуне"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CSS-H9G51PG"
      },
      "source": [
        "chugun_train.drop(chugun_train[chugun_train.NPLV == 512233].index,inplace=True)\n",
        "chugun_train.drop(chugun_train[chugun_train.NPLV == 511135].index, inplace=True)\n",
        "chugun_train.drop(chugun_train[chugun_train.NPLV == 511156].index, inplace=True)\n",
        "chugun_train.drop(chugun_train[chugun_train.NPLV == 512299].index, inplace=True)\n",
        "chugun_train.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtSJ2rkQ3ZsW"
      },
      "source": [
        "gas_test = pd.read_csv('/content/drive/MyDrive/Evraz/task1/task1/data_task1/data_task1/gas_test.csv')\n",
        "gas_test_new = gas_test.groupby('NPLV').agg({'O2_pressure':'mean', 'T фурмы 2':'mean', 'T фурмы 1':'mean','AR':'mean', 'CO': 'mean', 'CO2':'median', 'H2':'median', 'N2':'mean', 'O2':'median', 'T':'mean', 'V':'mean'}).reset_index()\n",
        "gas_train = pd.read_csv('/content/drive/MyDrive/Evraz/task1/task1/data_task1/data_task1/gas_train.csv')\n",
        "gas_train_new = gas_train.groupby('NPLV').agg({'O2_pressure':'mean', 'T фурмы 2':'mean', 'T фурмы 1':'mean','AR':'mean', 'CO': 'mean', 'CO2':'median', 'H2':'median', 'N2':'mean', 'O2':'median', 'T':'mean', 'V':'mean'}).reset_index()\n",
        "# O2_pressure\tДавление кислорода\n",
        "# T фурмы 2\tТемпература 2-ой фурмы\n",
        "# T фурмы 1\tТемпература 1-ой фурмы\n",
        "# AR\tдоля AR в отх. газах \n",
        "# CO\tдоля CO в отх. газах \n",
        "# CO2\tдоля CO2 в отх. газах \n",
        "# H2\tдоля H2 в отх. газах \n",
        "# N2\tдоля N2 в отх. газах \n",
        "# O2\tдоля O2 в отх. газах \n",
        "# T\tтемпература отходящих газов\n",
        "# V\tобъем выходящих газов\n",
        "# NPLV\tномер плавки\n",
        "# Time\tдата и время замера хим. состава отходящих газов"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COVSgwcVeUSB"
      },
      "source": [
        "gas_train_new.drop(gas_train_new[gas_train_new.NPLV == 512233].index,inplace=True)\n",
        "gas_train_new.drop(gas_train_new[gas_train_new.NPLV == 511135].index, inplace=True)\n",
        "gas_train_new.drop(gas_train_new[gas_train_new.NPLV == 511156].index, inplace=True)\n",
        "gas_train_new.drop(gas_train_new[gas_train_new.NPLV == 512299].index, inplace=True)\n",
        "gas_train_new.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bD8n1T03k6s"
      },
      "source": [
        "lom_test = pd.read_csv('/content/drive/MyDrive/Evraz/task1/task1/data_task1/data_task1/lom_test.csv')\n",
        "lom_train = pd.read_csv('/content/drive/MyDrive/Evraz/task1/task1/data_task1/data_task1/lom_train.csv')\n",
        "# NPLV\tномер плавки\n",
        "# VDL\tкод лома\n",
        "# NML\tнаименование лома\n",
        "# VES\tвес лома"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gmAj2eJBg5-"
      },
      "source": [
        "lom_all = concat(lom_train,lom_test)\n",
        "lom_all.drop('NML',1,inplace=True)\n",
        "lom_all = ekran_lom(lom_all)\n",
        "lom_all.drop(lom_all[lom_all.NPLV == 512233].index,inplace=True)\n",
        "lom_all.drop(lom_all[lom_all.NPLV == 511135].index, inplace=True)\n",
        "lom_all.drop(lom_all[lom_all.NPLV == 511156].index, inplace=True)\n",
        "lom_all.drop(lom_all[lom_all.NPLV == 512299].index, inplace=True)\n",
        "lom_all.NPLV = lom_all.NPLV.astype('int64')\n",
        "lom_all.VES = lom_all.VES.astype('int64')\n",
        "lom_all.reset_index(drop=True, inplace=True)\n",
        "lom_train_new, lom_test_new = separate(lom_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-TOs5Le387C"
      },
      "source": [
        "plavki_test = pd.read_csv('/content/drive/MyDrive/Evraz/task1/task1/data_task1/data_task1/plavki_test.csv')\n",
        "plavki_train = pd.read_csv('/content/drive/MyDrive/Evraz/task1/task1/data_task1/data_task1/plavki_train.csv')\n",
        "# plavka_VR_NACH\tвремя начала плавки\n",
        "# plavka_VR_KON\tвремя окончания плавки\n",
        "# plavka_NMZ\tмарка заданная \n",
        "# plavka_NAPR_ZAD\tнаправление разливки\n",
        "# plavka_STFUT\tстойкость футеровки конвертера\n",
        "# plavka_TIPE_FUR\tтип фурмы\n",
        "# plavka_ST_FURM\tстойкость фурмы\n",
        "# plavka_TIPE_GOL\tтип головки фурмы\n",
        "# plavka_ST_GOL\tстойкость головки фурмы"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mbRwd1G0qSr"
      },
      "source": [
        "plavki_all = concat(plavki_train, plavki_test)\n",
        "list_feat = ['plavka_NMZ','plavka_TIPE_FUR', 'plavka_TIPE_GOL', 'plavka_NAPR_ZAD']\n",
        "for i in list_feat:\n",
        "    plavki_all[i] = laben(plavki_all, i)\n",
        "plavki_all.drop(['plavka_NMZ','plavka_VR_NACH', 'plavka_VR_KON', 'plavka_STFUT'], 1, inplace=True)\n",
        "plavki_all.drop(plavki_all[plavki_all.NPLV == 512233].index,inplace=True)\n",
        "plavki_all.drop(plavki_all[plavki_all.NPLV == 511135].index, inplace=True)\n",
        "plavki_all.drop(plavki_all[plavki_all.NPLV == 511156].index, inplace=True)\n",
        "plavki_all.drop(plavki_all[plavki_all.NPLV == 512299].index, inplace=True)\n",
        "plavki_all.reset_index(drop=True, inplace=True)\n",
        "plavki_train_new, plavki_test_new = separate(plavki_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8Enou814JZn"
      },
      "source": [
        "produv_test = pd.read_csv('/content/drive/MyDrive/Evraz/task1/task1/data_task1/data_task1/produv_test.csv')\n",
        "produv_train = pd.read_csv('/content/drive/MyDrive/Evraz/task1/task1/data_task1/data_task1/produv_train.csv')\n",
        "# NPLV\tномер плавки\n",
        "# SEC\tвремя измерения\n",
        "# RAS\tрасход кислорода на продувку\n",
        "# POL\tположение фурмы для продувки"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq2vPIN5Q6ef"
      },
      "source": [
        "produv_all = concat(produv_train, produv_test)\n",
        "produv_all.drop('SEC',1,inplace=True)\n",
        "produv_all = ekran_produv(produv_all)\n",
        "produv_all.drop(produv_all[produv_all.NPLV == 512233].index,inplace=True)\n",
        "produv_all.drop(produv_all[produv_all.NPLV == 511135].index, inplace=True)\n",
        "produv_all.drop(produv_all[produv_all.NPLV == 511156].index, inplace=True)\n",
        "produv_all.drop(produv_all[produv_all.NPLV == 512299].index, inplace=True)\n",
        "produv_all.reset_index(drop=True, inplace=True)\n",
        "produv_train_new, produv_test_new = separate(produv_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re8LT0jn4Xl4"
      },
      "source": [
        "sample_submission = pd.read_csv('/content/drive/MyDrive/Evraz/task1/task1/data_task1/data_task1/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwqUKr774lqU"
      },
      "source": [
        "sip_test = pd.read_csv('/content/drive/MyDrive/Evraz/task1/task1/data_task1/data_task1/sip_test.csv')\n",
        "sip_train = pd.read_csv('/content/drive/MyDrive/Evraz/task1/task1/data_task1/data_task1/sip_train.csv')\n",
        "# NPLV\tномер плавки\n",
        "# VDSYP\tвид сыпучих\n",
        "# NMSYP\tнаименование сыпучих\n",
        "# VSSYP\tвес сыпучих\n",
        "# DAT_OTD\tдата и время отдачи"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzfliUvmK-Mn"
      },
      "source": [
        "sip_all = concat(sip_train,sip_test)\n",
        "sip_all.drop('NMSYP',1, inplace=True)\n",
        "sip_all.DAT_OTD = datet(sip_all, 'DAT_OTD')\n",
        "sip_all = ekran_sip(sip_all)\n",
        "sip_all.VDSYP = laben(sip_all, 'VDSYP')\n",
        "sip_all.drop(sip_all[sip_all.NPLV == 512233].index,inplace=True)\n",
        "sip_all.drop(sip_all[sip_all.NPLV == 511135].index, inplace=True)\n",
        "sip_all.drop(sip_all[sip_all.NPLV == 511156].index, inplace=True)\n",
        "sip_all.drop(sip_all[sip_all.NPLV == 512299].index, inplace=True)\n",
        "sip_all.reset_index(drop=True, inplace=True)\n",
        "sip_all.VSSYP = sip_all.VSSYP.astype('int64')\n",
        "sip_train_new, sip_test_new = separate(sip_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-_wI6Ih4xx_"
      },
      "source": [
        "target_train = pd.read_csv('/content/drive/MyDrive/Evraz/task1/task1/data_task1/data_task1/target_train.csv')\n",
        "target_train = target_train.dropna()\n",
        "target_train.drop(target_train[target_train.NPLV == 511135].index, inplace=True)\n",
        "target_train.reset_index(drop=True, inplace=True)\n",
        "# C\tсодержание углерода в металле\n",
        "# TST\tтемпература металла\n",
        "# NPLV\tномер плавки"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0R1Bd_nfT73"
      },
      "source": [
        "all_tables_train = chronom_train_new.merge(chugun_train, on='NPLV')\n",
        "all_tables_train = all_tables_train.merge(gas_train_new, on='NPLV')\n",
        "all_tables_train = all_tables_train.merge(lom_train_new, on='NPLV')\n",
        "all_tables_train = all_tables_train.merge(plavki_train_new, on='NPLV')\n",
        "all_tables_train = all_tables_train.merge(produv_train_new, on='NPLV')\n",
        "all_tables_train = all_tables_train.merge(sip_train_new, on='NPLV')\n",
        "all_tables_train = all_tables_train.merge(target_train, on='NPLV')\n",
        "all_tables_train.drop('NPLV',1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1hZWFmLKTxz"
      },
      "source": [
        "all_tables_test = chronom_test_new.merge(chugun_test, on='NPLV')\n",
        "all_tables_test = all_tables_test.merge(gas_test_new, on='NPLV')\n",
        "all_tables_test = all_tables_test.merge(lom_test_new, on='NPLV')\n",
        "all_tables_test = all_tables_test.merge(plavki_test_new, on='NPLV')\n",
        "all_tables_test = all_tables_test.merge(produv_test_new, on='NPLV')\n",
        "all_tables_test = all_tables_test.merge(sip_test_new, on='NPLV')\n",
        "all_tables_test.drop('NPLV',1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "7oDo1LpqTLlj",
        "outputId": "140e7f58-bcf1-433a-a9ba-2523ab6b261e"
      },
      "source": [
        "fig, ax = plt.subplots(1,2, figsize= (15,5))\n",
        "sm.qqplot(all_tables_train.TST, stats.t, distargs=(4,),fit=True, line=\"45\", ax = ax[0])\n",
        "sns.distplot(all_tables_train.TST, kde = True, hist=True, fit = norm, ax = ax[1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "toaDnaDf-QBD",
        "outputId": "f9c3df9a-f1f6-4663-aac9-232ae971709b"
      },
      "source": [
        "fig, ax = plt.subplots(1,2, figsize= (15,5))\n",
        "sm.qqplot(np.log(all_tables_train.C), stats.t, distargs=(4,),fit=True, line=\"45\", ax = ax[0])\n",
        "sns.distplot(np.log(all_tables_train.C), kde = True, hist=True, fit = norm, ax = ax[1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QP1vtygAU1U"
      },
      "source": [
        "all_tables_train_number = all_tables_train.select_dtypes(exclude=[object])\n",
        "all_tables_train_str = all_tables_train.select_dtypes(include=[object])\n",
        "all_tables_test_number = all_tables_test.select_dtypes(exclude=[object])\n",
        "all_tables_tets_str = all_tables_test.select_dtypes(include=[object])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE6HBYNk98IO"
      },
      "source": [
        "X_tr = all_tables_train_number.drop(['C','TST'],1)\n",
        "y_1 = all_tables_train_number['TST']\n",
        "y_2 = np.log(all_tables_train_number['C'])\n",
        "standart = StandardScaler()\n",
        "X_tr = standart.fit_transform(X_tr)\n",
        "X_train_1, X_valid_1, y_train_1, y_valid_1 = train_test_split(X_tr, y_1, test_size=0.33, random_state=42)\n",
        "X_train_2, X_valid_2, y_train_2, y_valid_2 = train_test_split(X_tr, y_2, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8GaT9wBT9vj"
      },
      "source": [
        "X_ts = all_tables_test_number\n",
        "X_ts = standart.transform(X_ts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha2jb9du7saq",
        "outputId": "adefe9b7-b047-4b07-a8d2-86e1d121978f"
      },
      "source": [
        "automl_1 = AutoML()\n",
        "settings_1 = {\n",
        "    \"time_budget\": 180,\n",
        "    \"metric\": 'r2',\n",
        "    \"estimator_list\": ['lgbm', 'xgboost', 'catboost'],\n",
        "    \"task\": 'regression'}                           \n",
        "automl_1.fit(X_train=X_train_1, y_train=y_train_1, X_val=X_valid_1, y_val=y_valid_1, **settings_1)  \n",
        "\n",
        "print('Лучшие гиперпараметры для TST:', automl_1.best_config)\n",
        "print(f'Лучшая метрика для TST: {automl_1.best_loss}')\n",
        "print(f'Время на обучение для TST: {automl_1.best_config_train_time} s')\n",
        "\n",
        "automl_1.model\n",
        "y_pred_1 = automl_1.predict(X_valid_1)\n",
        "print('score для TST', '=', (mean_absolute_error(y_valid_1, y_pred_1))) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 10-31 07:50:28] {1463} INFO - Data split method: uniform\n",
            "[flaml.automl: 10-31 07:50:28] {1467} INFO - Evaluation method: holdout\n",
            "[flaml.automl: 10-31 07:50:28] {1515} INFO - Minimizing error metric: 1-r2\n",
            "[flaml.automl: 10-31 07:50:28] {1552} INFO - List of ML learners in AutoML Run: ['lgbm', 'xgboost', 'catboost']\n",
            "[flaml.automl: 10-31 07:50:28] {1793} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:28] {1911} INFO - Estimated sufficient time budget=3877s. Estimated necessary time budget=7s.\n",
            "[flaml.automl: 10-31 07:50:28] {1987} INFO -  at 0.4s,\testimator lgbm's best error=0.8109,\tbest estimator lgbm's best error=0.8109\n",
            "[flaml.automl: 10-31 07:50:28] {1793} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:28] {1987} INFO -  at 0.4s,\testimator lgbm's best error=0.8109,\tbest estimator lgbm's best error=0.8109\n",
            "[flaml.automl: 10-31 07:50:28] {1793} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:28] {1987} INFO -  at 0.4s,\testimator lgbm's best error=0.6883,\tbest estimator lgbm's best error=0.6883\n",
            "[flaml.automl: 10-31 07:50:28] {1793} INFO - iteration 3, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:28] {1987} INFO -  at 0.5s,\testimator lgbm's best error=0.6081,\tbest estimator lgbm's best error=0.6081\n",
            "[flaml.automl: 10-31 07:50:28] {1793} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:28] {1987} INFO -  at 0.5s,\testimator lgbm's best error=0.6081,\tbest estimator lgbm's best error=0.6081\n",
            "[flaml.automl: 10-31 07:50:28] {1793} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:29] {1987} INFO -  at 0.5s,\testimator lgbm's best error=0.6081,\tbest estimator lgbm's best error=0.6081\n",
            "[flaml.automl: 10-31 07:50:29] {1793} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:29] {1987} INFO -  at 0.6s,\testimator lgbm's best error=0.5776,\tbest estimator lgbm's best error=0.5776\n",
            "[flaml.automl: 10-31 07:50:29] {1793} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:29] {1987} INFO -  at 0.6s,\testimator lgbm's best error=0.5776,\tbest estimator lgbm's best error=0.5776\n",
            "[flaml.automl: 10-31 07:50:29] {1793} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:29] {1987} INFO -  at 0.6s,\testimator lgbm's best error=0.5776,\tbest estimator lgbm's best error=0.5776\n",
            "[flaml.automl: 10-31 07:50:29] {1793} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:29] {1987} INFO -  at 0.7s,\testimator lgbm's best error=0.5776,\tbest estimator lgbm's best error=0.5776\n",
            "[flaml.automl: 10-31 07:50:29] {1793} INFO - iteration 10, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:29] {1987} INFO -  at 0.7s,\testimator lgbm's best error=0.5551,\tbest estimator lgbm's best error=0.5551\n",
            "[flaml.automl: 10-31 07:50:29] {1793} INFO - iteration 11, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:29] {1987} INFO -  at 0.8s,\testimator lgbm's best error=0.5551,\tbest estimator lgbm's best error=0.5551\n",
            "[flaml.automl: 10-31 07:50:29] {1793} INFO - iteration 12, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:29] {1987} INFO -  at 0.8s,\testimator lgbm's best error=0.5551,\tbest estimator lgbm's best error=0.5551\n",
            "[flaml.automl: 10-31 07:50:29] {1793} INFO - iteration 13, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:29] {1987} INFO -  at 0.8s,\testimator lgbm's best error=0.5551,\tbest estimator lgbm's best error=0.5551\n",
            "[flaml.automl: 10-31 07:50:29] {1793} INFO - iteration 14, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:29] {1987} INFO -  at 0.9s,\testimator lgbm's best error=0.5551,\tbest estimator lgbm's best error=0.5551\n",
            "[flaml.automl: 10-31 07:50:29] {1793} INFO - iteration 15, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:29] {1987} INFO -  at 1.0s,\testimator lgbm's best error=0.5551,\tbest estimator lgbm's best error=0.5551\n",
            "[flaml.automl: 10-31 07:50:29] {1793} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:29] {1987} INFO -  at 1.0s,\testimator lgbm's best error=0.5551,\tbest estimator lgbm's best error=0.5551\n",
            "[flaml.automl: 10-31 07:50:29] {1793} INFO - iteration 17, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:29] {1987} INFO -  at 1.1s,\testimator lgbm's best error=0.5551,\tbest estimator lgbm's best error=0.5551\n",
            "[flaml.automl: 10-31 07:50:29] {1793} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:29] {1987} INFO -  at 1.1s,\testimator lgbm's best error=0.5551,\tbest estimator lgbm's best error=0.5551\n",
            "[flaml.automl: 10-31 07:50:29] {1793} INFO - iteration 19, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:29] {1987} INFO -  at 1.2s,\testimator lgbm's best error=0.5551,\tbest estimator lgbm's best error=0.5551\n",
            "[flaml.automl: 10-31 07:50:29] {1793} INFO - iteration 20, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:29] {1987} INFO -  at 1.2s,\testimator lgbm's best error=0.5551,\tbest estimator lgbm's best error=0.5551\n",
            "[flaml.automl: 10-31 07:50:29] {1793} INFO - iteration 21, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:29] {1987} INFO -  at 1.3s,\testimator lgbm's best error=0.5469,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:29] {1793} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:29] {1987} INFO -  at 1.3s,\testimator lgbm's best error=0.5469,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:29] {1793} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:29] {1987} INFO -  at 1.4s,\testimator lgbm's best error=0.5469,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:29] {1793} INFO - iteration 24, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:29] {1987} INFO -  at 1.4s,\testimator lgbm's best error=0.5469,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:29] {1793} INFO - iteration 25, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:30] {1987} INFO -  at 1.5s,\testimator lgbm's best error=0.5469,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:30] {1793} INFO - iteration 26, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:30] {1987} INFO -  at 1.6s,\testimator lgbm's best error=0.5469,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:30] {1793} INFO - iteration 27, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:30] {1987} INFO -  at 1.6s,\testimator lgbm's best error=0.5469,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:30] {1793} INFO - iteration 28, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:30] {1987} INFO -  at 1.7s,\testimator lgbm's best error=0.5469,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:30] {1793} INFO - iteration 29, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:30] {1987} INFO -  at 1.7s,\testimator lgbm's best error=0.5469,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:30] {1793} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:30] {1987} INFO -  at 1.8s,\testimator lgbm's best error=0.5469,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:30] {1793} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:30] {1987} INFO -  at 1.8s,\testimator lgbm's best error=0.5469,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:30] {1793} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:30] {1987} INFO -  at 1.9s,\testimator lgbm's best error=0.5469,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:30] {1793} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:30] {1987} INFO -  at 1.9s,\testimator lgbm's best error=0.5469,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:30] {1793} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:30] {1987} INFO -  at 2.0s,\testimator lgbm's best error=0.5469,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:30] {1793} INFO - iteration 35, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 2.6s,\testimator xgboost's best error=1281.6931,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 36, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 2.6s,\testimator xgboost's best error=1281.6931,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 37, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 2.8s,\testimator lgbm's best error=0.5469,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 38, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 2.8s,\testimator xgboost's best error=271.0012,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 39, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 2.8s,\testimator xgboost's best error=0.6619,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 40, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 2.9s,\testimator lgbm's best error=0.5469,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 41, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 2.9s,\testimator xgboost's best error=0.6619,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 42, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 2.9s,\testimator xgboost's best error=0.6619,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 43, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 2.9s,\testimator xgboost's best error=0.6619,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 44, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 3.0s,\testimator xgboost's best error=0.6619,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 45, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 3.0s,\testimator xgboost's best error=0.6619,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 46, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 3.0s,\testimator xgboost's best error=0.6619,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 47, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 3.0s,\testimator xgboost's best error=0.6619,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 48, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 3.0s,\testimator xgboost's best error=0.6619,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 49, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 3.1s,\testimator xgboost's best error=0.6062,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 50, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 3.1s,\testimator xgboost's best error=0.6062,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 51, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 3.2s,\testimator lgbm's best error=0.5469,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 52, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 3.2s,\testimator lgbm's best error=0.5469,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 53, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 3.3s,\testimator xgboost's best error=0.6062,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 3.5s,\testimator lgbm's best error=0.5469,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 55, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 3.5s,\testimator xgboost's best error=0.6062,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 56, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:31] {1987} INFO -  at 3.5s,\testimator xgboost's best error=0.6062,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:31] {1793} INFO - iteration 57, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:32] {1987} INFO -  at 3.5s,\testimator lgbm's best error=0.5469,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:32] {1793} INFO - iteration 58, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:32] {1987} INFO -  at 3.6s,\testimator xgboost's best error=0.6062,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:32] {1793} INFO - iteration 59, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:32] {1987} INFO -  at 3.6s,\testimator lgbm's best error=0.5469,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:32] {1793} INFO - iteration 60, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:32] {1987} INFO -  at 3.6s,\testimator xgboost's best error=0.6062,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:32] {1793} INFO - iteration 61, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:32] {1987} INFO -  at 3.7s,\testimator xgboost's best error=0.6062,\tbest estimator lgbm's best error=0.5469\n",
            "[flaml.automl: 10-31 07:50:32] {1793} INFO - iteration 62, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:32] {1987} INFO -  at 3.8s,\testimator lgbm's best error=0.5419,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:32] {1793} INFO - iteration 63, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:32] {1987} INFO -  at 3.8s,\testimator xgboost's best error=0.6062,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:32] {1793} INFO - iteration 64, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:32] {1987} INFO -  at 3.9s,\testimator xgboost's best error=0.6062,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:32] {1793} INFO - iteration 65, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:32] {1987} INFO -  at 3.9s,\testimator xgboost's best error=0.6062,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:32] {1793} INFO - iteration 66, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:32] {1987} INFO -  at 4.1s,\testimator lgbm's best error=0.5419,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:32] {1793} INFO - iteration 67, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:32] {1987} INFO -  at 4.1s,\testimator xgboost's best error=0.6062,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:32] {1793} INFO - iteration 68, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:32] {1987} INFO -  at 4.2s,\testimator xgboost's best error=0.6062,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:32] {1793} INFO - iteration 69, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:32] {1987} INFO -  at 4.2s,\testimator xgboost's best error=0.6062,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:32] {1793} INFO - iteration 70, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:32] {1987} INFO -  at 4.2s,\testimator xgboost's best error=0.5932,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:32] {1793} INFO - iteration 71, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:32] {1987} INFO -  at 4.3s,\testimator lgbm's best error=0.5419,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:32] {1793} INFO - iteration 72, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:32] {1987} INFO -  at 4.4s,\testimator xgboost's best error=0.5932,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:32] {1793} INFO - iteration 73, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:32] {1987} INFO -  at 4.4s,\testimator lgbm's best error=0.5419,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:32] {1793} INFO - iteration 74, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:33] {1987} INFO -  at 4.8s,\testimator lgbm's best error=0.5419,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:33] {1793} INFO - iteration 75, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:33] {1987} INFO -  at 4.9s,\testimator xgboost's best error=0.5932,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:33] {1793} INFO - iteration 76, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:33] {1987} INFO -  at 4.9s,\testimator lgbm's best error=0.5419,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:33] {1793} INFO - iteration 77, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:33] {1987} INFO -  at 5.4s,\testimator lgbm's best error=0.5419,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:33] {1793} INFO - iteration 78, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:33] {1987} INFO -  at 5.4s,\testimator xgboost's best error=0.5932,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:33] {1793} INFO - iteration 79, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:33] {1987} INFO -  at 5.4s,\testimator lgbm's best error=0.5419,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:33] {1793} INFO - iteration 80, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:34] {1987} INFO -  at 5.5s,\testimator xgboost's best error=0.5676,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:34] {1793} INFO - iteration 81, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:34] {1987} INFO -  at 5.6s,\testimator xgboost's best error=0.5676,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:34] {1793} INFO - iteration 82, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:34] {1987} INFO -  at 5.7s,\testimator xgboost's best error=0.5676,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:34] {1793} INFO - iteration 83, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:34] {1987} INFO -  at 5.7s,\testimator xgboost's best error=0.5676,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:34] {1793} INFO - iteration 84, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:34] {1987} INFO -  at 5.8s,\testimator xgboost's best error=0.5676,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:34] {1793} INFO - iteration 85, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:34] {1987} INFO -  at 6.4s,\testimator lgbm's best error=0.5419,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:34] {1793} INFO - iteration 86, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:35] {1987} INFO -  at 6.7s,\testimator lgbm's best error=0.5419,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:35] {1793} INFO - iteration 87, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:35] {1987} INFO -  at 7.0s,\testimator xgboost's best error=0.5676,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:35] {1793} INFO - iteration 88, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:35] {1987} INFO -  at 7.0s,\testimator xgboost's best error=0.5676,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:35] {1793} INFO - iteration 89, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:35] {1987} INFO -  at 7.1s,\testimator xgboost's best error=0.5676,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:35] {1793} INFO - iteration 90, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:35] {1987} INFO -  at 7.2s,\testimator xgboost's best error=0.5676,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:35] {1793} INFO - iteration 91, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:35] {1987} INFO -  at 7.3s,\testimator xgboost's best error=0.5676,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:35] {1793} INFO - iteration 92, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:35] {1987} INFO -  at 7.3s,\testimator lgbm's best error=0.5419,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:35] {1793} INFO - iteration 93, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:35] {1987} INFO -  at 7.4s,\testimator xgboost's best error=0.5676,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:35] {1793} INFO - iteration 94, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:36] {1987} INFO -  at 7.8s,\testimator lgbm's best error=0.5419,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:36] {1793} INFO - iteration 95, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:36] {1987} INFO -  at 7.8s,\testimator xgboost's best error=0.5676,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:36] {1793} INFO - iteration 96, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:36] {1987} INFO -  at 7.9s,\testimator lgbm's best error=0.5419,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:36] {1793} INFO - iteration 97, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:36] {1987} INFO -  at 8.1s,\testimator lgbm's best error=0.5419,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:36] {1793} INFO - iteration 98, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:36] {1987} INFO -  at 8.2s,\testimator xgboost's best error=0.5676,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:36] {1793} INFO - iteration 99, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:36] {1987} INFO -  at 8.2s,\testimator xgboost's best error=0.5676,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:36] {1793} INFO - iteration 100, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:36] {1987} INFO -  at 8.4s,\testimator lgbm's best error=0.5419,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:36] {1793} INFO - iteration 101, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:37] {1987} INFO -  at 8.5s,\testimator xgboost's best error=0.5676,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:37] {1793} INFO - iteration 102, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:37] {1987} INFO -  at 8.7s,\testimator lgbm's best error=0.5419,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:37] {1793} INFO - iteration 103, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:37] {1987} INFO -  at 8.8s,\testimator xgboost's best error=0.5676,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:37] {1793} INFO - iteration 104, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:37] {1987} INFO -  at 8.8s,\testimator xgboost's best error=0.5676,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:37] {1793} INFO - iteration 105, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:37] {1987} INFO -  at 9.0s,\testimator lgbm's best error=0.5419,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:37] {1793} INFO - iteration 106, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:37] {1987} INFO -  at 9.0s,\testimator xgboost's best error=0.5676,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:37] {1793} INFO - iteration 107, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:37] {1987} INFO -  at 9.1s,\testimator xgboost's best error=0.5647,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:37] {1793} INFO - iteration 108, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:37] {1987} INFO -  at 9.2s,\testimator lgbm's best error=0.5419,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:37] {1793} INFO - iteration 109, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:37] {1987} INFO -  at 9.4s,\testimator xgboost's best error=0.5636,\tbest estimator lgbm's best error=0.5419\n",
            "[flaml.automl: 10-31 07:50:37] {1793} INFO - iteration 110, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:38] {1987} INFO -  at 9.6s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:38] {1793} INFO - iteration 111, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:38] {1987} INFO -  at 10.0s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:38] {1793} INFO - iteration 112, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:38] {1987} INFO -  at 10.0s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:38] {1793} INFO - iteration 113, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:38] {1987} INFO -  at 10.2s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:38] {1793} INFO - iteration 114, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:38] {1987} INFO -  at 10.4s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:38] {1793} INFO - iteration 115, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:39] {1987} INFO -  at 10.6s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:39] {1793} INFO - iteration 116, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:39] {1987} INFO -  at 11.0s,\testimator lgbm's best error=0.5419,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:39] {1793} INFO - iteration 117, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:39] {1987} INFO -  at 11.1s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:39] {1793} INFO - iteration 118, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:40] {1987} INFO -  at 11.6s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:40] {1793} INFO - iteration 119, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:40] {1987} INFO -  at 11.7s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:40] {1793} INFO - iteration 120, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:40] {1987} INFO -  at 11.8s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:40] {1793} INFO - iteration 121, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:40] {1987} INFO -  at 12.2s,\testimator lgbm's best error=0.5419,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:40] {1793} INFO - iteration 122, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:40] {1987} INFO -  at 12.3s,\testimator lgbm's best error=0.5419,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:40] {1793} INFO - iteration 123, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:41] {1987} INFO -  at 12.6s,\testimator lgbm's best error=0.5419,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:41] {1793} INFO - iteration 124, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:41] {1987} INFO -  at 12.7s,\testimator lgbm's best error=0.5419,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:41] {1793} INFO - iteration 125, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:41] {1987} INFO -  at 12.8s,\testimator lgbm's best error=0.5419,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:41] {1793} INFO - iteration 126, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:41] {1987} INFO -  at 13.0s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:41] {1793} INFO - iteration 127, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:41] {1987} INFO -  at 13.3s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:41] {1793} INFO - iteration 128, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:41] {1987} INFO -  at 13.4s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:41] {1793} INFO - iteration 129, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:42] {1987} INFO -  at 13.6s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:42] {1793} INFO - iteration 130, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:42] {1987} INFO -  at 13.8s,\testimator lgbm's best error=0.5419,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:42] {1793} INFO - iteration 131, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:42] {1987} INFO -  at 13.9s,\testimator lgbm's best error=0.5419,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:42] {1793} INFO - iteration 132, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:42] {1987} INFO -  at 14.0s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:42] {1793} INFO - iteration 133, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:42] {1987} INFO -  at 14.1s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:42] {1793} INFO - iteration 134, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:42] {1987} INFO -  at 14.5s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:42] {1793} INFO - iteration 135, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:43] {1987} INFO -  at 14.7s,\testimator lgbm's best error=0.5419,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:43] {1793} INFO - iteration 136, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:43] {1987} INFO -  at 14.9s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:43] {1793} INFO - iteration 137, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:43] {1987} INFO -  at 15.2s,\testimator lgbm's best error=0.5419,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:43] {1793} INFO - iteration 138, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:43] {1987} INFO -  at 15.3s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:43] {1793} INFO - iteration 139, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:43] {1987} INFO -  at 15.4s,\testimator lgbm's best error=0.5419,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:43] {1793} INFO - iteration 140, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:44] {1987} INFO -  at 15.9s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:44] {1793} INFO - iteration 141, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:44] {1987} INFO -  at 16.0s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:44] {1793} INFO - iteration 142, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:44] {1987} INFO -  at 16.1s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:44] {1793} INFO - iteration 143, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:44] {1987} INFO -  at 16.3s,\testimator lgbm's best error=0.5419,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:44] {1793} INFO - iteration 144, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:44] {1987} INFO -  at 16.4s,\testimator lgbm's best error=0.5419,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:44] {1793} INFO - iteration 145, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:44] {1987} INFO -  at 16.4s,\testimator lgbm's best error=0.5419,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:44] {1793} INFO - iteration 146, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:45] {1987} INFO -  at 17.0s,\testimator lgbm's best error=0.5419,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:45] {1793} INFO - iteration 147, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:45] {1987} INFO -  at 17.3s,\testimator lgbm's best error=0.5419,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:45] {1793} INFO - iteration 148, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:45] {1987} INFO -  at 17.4s,\testimator lgbm's best error=0.5419,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:45] {1793} INFO - iteration 149, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:46] {1987} INFO -  at 17.5s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:46] {1793} INFO - iteration 150, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:46] {1987} INFO -  at 17.7s,\testimator xgboost's best error=0.5418,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:46] {1793} INFO - iteration 151, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:46] {1987} INFO -  at 17.7s,\testimator lgbm's best error=0.5419,\tbest estimator xgboost's best error=0.5418\n",
            "[flaml.automl: 10-31 07:50:46] {1793} INFO - iteration 152, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:46] {1987} INFO -  at 18.1s,\testimator lgbm's best error=0.5382,\tbest estimator lgbm's best error=0.5382\n",
            "[flaml.automl: 10-31 07:50:46] {1793} INFO - iteration 153, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:46] {1987} INFO -  at 18.3s,\testimator xgboost's best error=0.5418,\tbest estimator lgbm's best error=0.5382\n",
            "[flaml.automl: 10-31 07:50:46] {1793} INFO - iteration 154, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:46] {1987} INFO -  at 18.4s,\testimator xgboost's best error=0.5418,\tbest estimator lgbm's best error=0.5382\n",
            "[flaml.automl: 10-31 07:50:46] {1793} INFO - iteration 155, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:47] {1987} INFO -  at 19.1s,\testimator lgbm's best error=0.5382,\tbest estimator lgbm's best error=0.5382\n",
            "[flaml.automl: 10-31 07:50:47] {1793} INFO - iteration 156, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:47] {1987} INFO -  at 19.3s,\testimator lgbm's best error=0.5382,\tbest estimator lgbm's best error=0.5382\n",
            "[flaml.automl: 10-31 07:50:47] {1793} INFO - iteration 157, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:48] {1987} INFO -  at 19.5s,\testimator xgboost's best error=0.5418,\tbest estimator lgbm's best error=0.5382\n",
            "[flaml.automl: 10-31 07:50:48] {1793} INFO - iteration 158, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:49] {1987} INFO -  at 20.8s,\testimator lgbm's best error=0.5382,\tbest estimator lgbm's best error=0.5382\n",
            "[flaml.automl: 10-31 07:50:49] {1793} INFO - iteration 159, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:49] {1987} INFO -  at 21.0s,\testimator xgboost's best error=0.5418,\tbest estimator lgbm's best error=0.5382\n",
            "[flaml.automl: 10-31 07:50:49] {1793} INFO - iteration 160, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:49] {1987} INFO -  at 21.0s,\testimator xgboost's best error=0.5418,\tbest estimator lgbm's best error=0.5382\n",
            "[flaml.automl: 10-31 07:50:49] {1793} INFO - iteration 161, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:49] {1987} INFO -  at 21.2s,\testimator xgboost's best error=0.5299,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:49] {1793} INFO - iteration 162, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:49] {1987} INFO -  at 21.4s,\testimator xgboost's best error=0.5299,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:49] {1793} INFO - iteration 163, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:50] {1987} INFO -  at 21.6s,\testimator xgboost's best error=0.5299,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:50] {1793} INFO - iteration 164, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:50] {1987} INFO -  at 21.8s,\testimator xgboost's best error=0.5299,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:50] {1793} INFO - iteration 165, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:50] {1987} INFO -  at 22.0s,\testimator xgboost's best error=0.5299,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:50] {1793} INFO - iteration 166, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:50] {1987} INFO -  at 22.2s,\testimator xgboost's best error=0.5299,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:50] {1793} INFO - iteration 167, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:50] {1987} INFO -  at 22.4s,\testimator lgbm's best error=0.5382,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:50] {1793} INFO - iteration 168, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:51] {1987} INFO -  at 22.8s,\testimator lgbm's best error=0.5382,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:51] {1793} INFO - iteration 169, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:51] {1987} INFO -  at 22.9s,\testimator xgboost's best error=0.5299,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:51] {1793} INFO - iteration 170, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:51] {1987} INFO -  at 23.4s,\testimator xgboost's best error=0.5299,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:51] {1793} INFO - iteration 171, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:52] {1987} INFO -  at 23.7s,\testimator xgboost's best error=0.5299,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:52] {1793} INFO - iteration 172, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:52] {1987} INFO -  at 23.8s,\testimator xgboost's best error=0.5299,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:52] {1793} INFO - iteration 173, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:52] {1987} INFO -  at 24.2s,\testimator xgboost's best error=0.5299,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:52] {1793} INFO - iteration 174, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:52] {1987} INFO -  at 24.3s,\testimator xgboost's best error=0.5299,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:52] {1793} INFO - iteration 175, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:53] {1987} INFO -  at 24.6s,\testimator xgboost's best error=0.5299,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:53] {1793} INFO - iteration 176, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:53] {1987} INFO -  at 24.7s,\testimator xgboost's best error=0.5299,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:53] {1793} INFO - iteration 177, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:53] {1987} INFO -  at 24.9s,\testimator xgboost's best error=0.5299,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:53] {1793} INFO - iteration 178, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:53] {1987} INFO -  at 25.2s,\testimator xgboost's best error=0.5299,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:53] {1793} INFO - iteration 179, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:54] {1987} INFO -  at 25.5s,\testimator xgboost's best error=0.5299,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:54] {1793} INFO - iteration 180, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:54] {1987} INFO -  at 25.8s,\testimator lgbm's best error=0.5382,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:54] {1793} INFO - iteration 181, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:54] {1987} INFO -  at 25.9s,\testimator xgboost's best error=0.5299,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:54] {1793} INFO - iteration 182, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:54] {1987} INFO -  at 26.0s,\testimator xgboost's best error=0.5299,\tbest estimator xgboost's best error=0.5299\n",
            "[flaml.automl: 10-31 07:50:54] {1793} INFO - iteration 183, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:54] {1987} INFO -  at 26.4s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:50:54] {1793} INFO - iteration 184, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:55] {1987} INFO -  at 26.8s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:50:55] {1793} INFO - iteration 185, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:55] {1987} INFO -  at 27.0s,\testimator lgbm's best error=0.5382,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:50:55] {1793} INFO - iteration 186, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:55] {1987} INFO -  at 27.2s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:50:55] {1793} INFO - iteration 187, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:56] {1987} INFO -  at 27.9s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:50:56] {1793} INFO - iteration 188, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:56] {1987} INFO -  at 28.1s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:50:56] {1793} INFO - iteration 189, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:56] {1987} INFO -  at 28.4s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:50:56] {1793} INFO - iteration 190, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:57] {1987} INFO -  at 28.7s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:50:57] {1793} INFO - iteration 191, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:57] {1987} INFO -  at 29.0s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:50:57] {1793} INFO - iteration 192, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:57] {1987} INFO -  at 29.2s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:50:57] {1793} INFO - iteration 193, current learner lgbm\n",
            "[flaml.automl: 10-31 07:50:58] {1987} INFO -  at 30.1s,\testimator lgbm's best error=0.5382,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:50:58] {1793} INFO - iteration 194, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:58] {1987} INFO -  at 30.2s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:50:58] {1793} INFO - iteration 195, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:59] {1987} INFO -  at 30.8s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:50:59] {1793} INFO - iteration 196, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:59] {1987} INFO -  at 31.2s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:50:59] {1793} INFO - iteration 197, current learner xgboost\n",
            "[flaml.automl: 10-31 07:50:59] {1987} INFO -  at 31.5s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:50:59] {1793} INFO - iteration 198, current learner lgbm\n",
            "[flaml.automl: 10-31 07:51:00] {1987} INFO -  at 31.8s,\testimator lgbm's best error=0.5382,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:00] {1793} INFO - iteration 199, current learner xgboost\n",
            "[flaml.automl: 10-31 07:51:00] {1987} INFO -  at 32.0s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:00] {1793} INFO - iteration 200, current learner xgboost\n",
            "[flaml.automl: 10-31 07:51:01] {1987} INFO -  at 32.6s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:01] {1793} INFO - iteration 201, current learner xgboost\n",
            "[flaml.automl: 10-31 07:51:01] {1987} INFO -  at 33.3s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:01] {1793} INFO - iteration 202, current learner xgboost\n",
            "[flaml.automl: 10-31 07:51:01] {1987} INFO -  at 33.4s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:01] {1793} INFO - iteration 203, current learner xgboost\n",
            "[flaml.automl: 10-31 07:51:02] {1987} INFO -  at 33.5s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:02] {1793} INFO - iteration 204, current learner xgboost\n",
            "[flaml.automl: 10-31 07:51:02] {1987} INFO -  at 34.4s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:02] {1793} INFO - iteration 205, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:03] {1987} INFO -  at 35.2s,\testimator catboost's best error=0.5463,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:03] {1793} INFO - iteration 206, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:04] {1987} INFO -  at 36.0s,\testimator catboost's best error=0.5375,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:04] {1793} INFO - iteration 207, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:05] {1987} INFO -  at 36.6s,\testimator catboost's best error=0.5375,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:05] {1793} INFO - iteration 208, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:06] {1987} INFO -  at 37.7s,\testimator catboost's best error=0.5360,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:06] {1793} INFO - iteration 209, current learner xgboost\n",
            "[flaml.automl: 10-31 07:51:06] {1987} INFO -  at 38.0s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:06] {1793} INFO - iteration 210, current learner xgboost\n",
            "[flaml.automl: 10-31 07:51:06] {1987} INFO -  at 38.3s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:06] {1793} INFO - iteration 211, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:07] {1987} INFO -  at 39.1s,\testimator catboost's best error=0.5360,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:07] {1793} INFO - iteration 212, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:09] {1987} INFO -  at 40.8s,\testimator catboost's best error=0.5347,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:09] {1793} INFO - iteration 213, current learner xgboost\n",
            "[flaml.automl: 10-31 07:51:09] {1987} INFO -  at 40.8s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:09] {1793} INFO - iteration 214, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:10] {1987} INFO -  at 42.2s,\testimator catboost's best error=0.5347,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:10] {1793} INFO - iteration 215, current learner xgboost\n",
            "[flaml.automl: 10-31 07:51:11] {1987} INFO -  at 42.9s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:11] {1793} INFO - iteration 216, current learner xgboost\n",
            "[flaml.automl: 10-31 07:51:11] {1987} INFO -  at 43.2s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:11] {1793} INFO - iteration 217, current learner xgboost\n",
            "[flaml.automl: 10-31 07:51:12] {1987} INFO -  at 43.6s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:12] {1793} INFO - iteration 218, current learner xgboost\n",
            "[flaml.automl: 10-31 07:51:12] {1987} INFO -  at 43.9s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:12] {1793} INFO - iteration 219, current learner lgbm\n",
            "[flaml.automl: 10-31 07:51:12] {1987} INFO -  at 44.1s,\testimator lgbm's best error=0.5382,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:12] {1793} INFO - iteration 220, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:13] {1987} INFO -  at 45.2s,\testimator catboost's best error=0.5347,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:13] {1793} INFO - iteration 221, current learner xgboost\n",
            "[flaml.automl: 10-31 07:51:13] {1987} INFO -  at 45.4s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:13] {1793} INFO - iteration 222, current learner lgbm\n",
            "[flaml.automl: 10-31 07:51:14] {1987} INFO -  at 45.7s,\testimator lgbm's best error=0.5382,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:14] {1793} INFO - iteration 223, current learner xgboost\n",
            "[flaml.automl: 10-31 07:51:14] {1987} INFO -  at 45.8s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:14] {1793} INFO - iteration 224, current learner xgboost\n",
            "[flaml.automl: 10-31 07:51:14] {1987} INFO -  at 46.3s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:14] {1793} INFO - iteration 225, current learner xgboost\n",
            "[flaml.automl: 10-31 07:51:14] {1987} INFO -  at 46.4s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:14] {1793} INFO - iteration 226, current learner xgboost\n",
            "[flaml.automl: 10-31 07:51:15] {1987} INFO -  at 46.8s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:15] {1793} INFO - iteration 227, current learner xgboost\n",
            "[flaml.automl: 10-31 07:51:15] {1987} INFO -  at 46.9s,\testimator xgboost's best error=0.5292,\tbest estimator xgboost's best error=0.5292\n",
            "[flaml.automl: 10-31 07:51:15] {1793} INFO - iteration 228, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:17] {1987} INFO -  at 49.3s,\testimator catboost's best error=0.5278,\tbest estimator catboost's best error=0.5278\n",
            "[flaml.automl: 10-31 07:51:17] {1793} INFO - iteration 229, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:18] {1987} INFO -  at 50.4s,\testimator catboost's best error=0.5278,\tbest estimator catboost's best error=0.5278\n",
            "[flaml.automl: 10-31 07:51:18] {1793} INFO - iteration 230, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:22] {1987} INFO -  at 53.8s,\testimator catboost's best error=0.5278,\tbest estimator catboost's best error=0.5278\n",
            "[flaml.automl: 10-31 07:51:22] {1793} INFO - iteration 231, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:24] {1987} INFO -  at 56.3s,\testimator catboost's best error=0.5278,\tbest estimator catboost's best error=0.5278\n",
            "[flaml.automl: 10-31 07:51:24] {1793} INFO - iteration 232, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:25] {1987} INFO -  at 57.5s,\testimator catboost's best error=0.5278,\tbest estimator catboost's best error=0.5278\n",
            "[flaml.automl: 10-31 07:51:25] {1793} INFO - iteration 233, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:29] {1987} INFO -  at 60.8s,\testimator catboost's best error=0.5278,\tbest estimator catboost's best error=0.5278\n",
            "[flaml.automl: 10-31 07:51:29] {1793} INFO - iteration 234, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:30] {1987} INFO -  at 62.2s,\testimator catboost's best error=0.5278,\tbest estimator catboost's best error=0.5278\n",
            "[flaml.automl: 10-31 07:51:30] {1793} INFO - iteration 235, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:31] {1987} INFO -  at 63.4s,\testimator catboost's best error=0.5278,\tbest estimator catboost's best error=0.5278\n",
            "[flaml.automl: 10-31 07:51:31] {1793} INFO - iteration 236, current learner xgboost\n",
            "[flaml.automl: 10-31 07:51:33] {1987} INFO -  at 64.6s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5278\n",
            "[flaml.automl: 10-31 07:51:33] {1793} INFO - iteration 237, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:35] {1987} INFO -  at 66.7s,\testimator catboost's best error=0.5278,\tbest estimator catboost's best error=0.5278\n",
            "[flaml.automl: 10-31 07:51:35] {1793} INFO - iteration 238, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:36] {1987} INFO -  at 68.4s,\testimator catboost's best error=0.5278,\tbest estimator catboost's best error=0.5278\n",
            "[flaml.automl: 10-31 07:51:36] {1793} INFO - iteration 239, current learner lgbm\n",
            "[flaml.automl: 10-31 07:51:37] {1987} INFO -  at 68.8s,\testimator lgbm's best error=0.5382,\tbest estimator catboost's best error=0.5278\n",
            "[flaml.automl: 10-31 07:51:37] {1793} INFO - iteration 240, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:40] {1987} INFO -  at 71.7s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:51:40] {1793} INFO - iteration 241, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:42] {1987} INFO -  at 74.2s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:51:42] {1793} INFO - iteration 242, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:44] {1987} INFO -  at 76.3s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:51:44] {1793} INFO - iteration 243, current learner xgboost\n",
            "[flaml.automl: 10-31 07:51:45] {1987} INFO -  at 76.7s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:51:45] {1793} INFO - iteration 244, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:49] {1987} INFO -  at 81.2s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:51:49] {1793} INFO - iteration 245, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:51] {1987} INFO -  at 82.7s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:51:51] {1793} INFO - iteration 246, current learner lgbm\n",
            "[flaml.automl: 10-31 07:51:51] {1987} INFO -  at 83.1s,\testimator lgbm's best error=0.5382,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:51:51] {1793} INFO - iteration 247, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:53] {1987} INFO -  at 84.9s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:51:53] {1793} INFO - iteration 248, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:56] {1987} INFO -  at 88.1s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:51:56] {1793} INFO - iteration 249, current learner lgbm\n",
            "[flaml.automl: 10-31 07:51:56] {1987} INFO -  at 88.5s,\testimator lgbm's best error=0.5382,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:51:56] {1793} INFO - iteration 250, current learner catboost\n",
            "[flaml.automl: 10-31 07:51:59] {1987} INFO -  at 90.6s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:51:59] {1793} INFO - iteration 251, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:02] {1987} INFO -  at 93.8s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:02] {1793} INFO - iteration 252, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:03] {1987} INFO -  at 95.1s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:03] {1793} INFO - iteration 253, current learner lgbm\n",
            "[flaml.automl: 10-31 07:52:03] {1987} INFO -  at 95.2s,\testimator lgbm's best error=0.5382,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:03] {1793} INFO - iteration 254, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:06] {1987} INFO -  at 98.3s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:06] {1793} INFO - iteration 255, current learner xgboost\n",
            "[flaml.automl: 10-31 07:52:07] {1987} INFO -  at 98.5s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:07] {1793} INFO - iteration 256, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:09] {1987} INFO -  at 100.9s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:09] {1793} INFO - iteration 257, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:12] {1987} INFO -  at 103.9s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:12] {1793} INFO - iteration 258, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:16] {1987} INFO -  at 107.5s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:16] {1793} INFO - iteration 259, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:17] {1987} INFO -  at 109.4s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:17] {1793} INFO - iteration 260, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:19] {1987} INFO -  at 111.4s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:19] {1793} INFO - iteration 261, current learner xgboost\n",
            "[flaml.automl: 10-31 07:52:20] {1987} INFO -  at 111.6s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:20] {1793} INFO - iteration 262, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:22] {1987} INFO -  at 114.0s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:22] {1793} INFO - iteration 263, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:24] {1987} INFO -  at 115.8s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:24] {1793} INFO - iteration 264, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:27] {1987} INFO -  at 119.2s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:27] {1793} INFO - iteration 265, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:29] {1987} INFO -  at 121.1s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:29] {1793} INFO - iteration 266, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:31] {1987} INFO -  at 123.2s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:31] {1793} INFO - iteration 267, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:33] {1987} INFO -  at 125.3s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:33] {1793} INFO - iteration 268, current learner xgboost\n",
            "[flaml.automl: 10-31 07:52:34] {1987} INFO -  at 125.9s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:34] {1793} INFO - iteration 269, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:36] {1987} INFO -  at 128.5s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:36] {1793} INFO - iteration 270, current learner xgboost\n",
            "[flaml.automl: 10-31 07:52:37] {1987} INFO -  at 128.6s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:37] {1793} INFO - iteration 271, current learner xgboost\n",
            "[flaml.automl: 10-31 07:52:37] {1987} INFO -  at 129.1s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:37] {1793} INFO - iteration 272, current learner xgboost\n",
            "[flaml.automl: 10-31 07:52:37] {1987} INFO -  at 129.3s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:37] {1793} INFO - iteration 273, current learner xgboost\n",
            "[flaml.automl: 10-31 07:52:38] {1987} INFO -  at 129.6s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:38] {1793} INFO - iteration 274, current learner xgboost\n",
            "[flaml.automl: 10-31 07:52:38] {1987} INFO -  at 129.8s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:38] {1793} INFO - iteration 275, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:39] {1987} INFO -  at 131.1s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:39] {1793} INFO - iteration 276, current learner xgboost\n",
            "[flaml.automl: 10-31 07:52:40] {1987} INFO -  at 131.5s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:40] {1793} INFO - iteration 277, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:43] {1987} INFO -  at 135.3s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:43] {1793} INFO - iteration 278, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:46] {1987} INFO -  at 137.7s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:46] {1793} INFO - iteration 279, current learner lgbm\n",
            "[flaml.automl: 10-31 07:52:46] {1987} INFO -  at 138.3s,\testimator lgbm's best error=0.5382,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:46] {1793} INFO - iteration 280, current learner xgboost\n",
            "[flaml.automl: 10-31 07:52:47] {1987} INFO -  at 138.8s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:47] {1793} INFO - iteration 281, current learner xgboost\n",
            "[flaml.automl: 10-31 07:52:47] {1987} INFO -  at 139.0s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:47] {1793} INFO - iteration 282, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:49] {1987} INFO -  at 141.0s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:49] {1793} INFO - iteration 283, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:52] {1987} INFO -  at 144.1s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:52] {1793} INFO - iteration 284, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:54] {1987} INFO -  at 145.9s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:54] {1793} INFO - iteration 285, current learner catboost\n",
            "[flaml.automl: 10-31 07:52:58] {1987} INFO -  at 149.6s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:58] {1793} INFO - iteration 286, current learner lgbm\n",
            "[flaml.automl: 10-31 07:52:58] {1987} INFO -  at 150.2s,\testimator lgbm's best error=0.5382,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:58] {1793} INFO - iteration 287, current learner lgbm\n",
            "[flaml.automl: 10-31 07:52:58] {1987} INFO -  at 150.4s,\testimator lgbm's best error=0.5382,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:52:58] {1793} INFO - iteration 288, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:00] {1987} INFO -  at 152.0s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:00] {1793} INFO - iteration 289, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:00] {1987} INFO -  at 152.2s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:00] {1793} INFO - iteration 290, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:02] {1987} INFO -  at 153.8s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:02] {1793} INFO - iteration 291, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:02] {1987} INFO -  at 154.1s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:02] {1793} INFO - iteration 292, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:05] {1987} INFO -  at 157.0s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:05] {1793} INFO - iteration 293, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:05] {1987} INFO -  at 157.3s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:05] {1793} INFO - iteration 294, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:07] {1987} INFO -  at 159.1s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:07] {1793} INFO - iteration 295, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:07] {1987} INFO -  at 159.5s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:07] {1793} INFO - iteration 296, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:08] {1987} INFO -  at 160.1s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:08] {1793} INFO - iteration 297, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:08] {1987} INFO -  at 160.5s,\testimator lgbm's best error=0.5382,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:08] {1793} INFO - iteration 298, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:09] {1987} INFO -  at 160.8s,\testimator lgbm's best error=0.5382,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:09] {1793} INFO - iteration 299, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:09] {1987} INFO -  at 161.0s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:09] {1793} INFO - iteration 300, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:09] {1987} INFO -  at 161.4s,\testimator lgbm's best error=0.5382,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:09] {1793} INFO - iteration 301, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:12] {1987} INFO -  at 163.7s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:12] {1793} INFO - iteration 302, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:12] {1987} INFO -  at 164.2s,\testimator lgbm's best error=0.5382,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:12] {1793} INFO - iteration 303, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:14] {1987} INFO -  at 165.6s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:14] {1793} INFO - iteration 304, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:16] {1987} INFO -  at 167.9s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:16] {1793} INFO - iteration 305, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:18] {1987} INFO -  at 169.8s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:18] {1793} INFO - iteration 306, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:18] {1987} INFO -  at 170.3s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:18] {1793} INFO - iteration 307, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:19] {1987} INFO -  at 170.8s,\testimator lgbm's best error=0.5382,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:19] {1793} INFO - iteration 308, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:19] {1987} INFO -  at 171.0s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:19] {1793} INFO - iteration 309, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:19] {1987} INFO -  at 171.4s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:19] {1793} INFO - iteration 310, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:20] {1987} INFO -  at 171.6s,\testimator lgbm's best error=0.5382,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:20] {1793} INFO - iteration 311, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:20] {1987} INFO -  at 171.8s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:20] {1793} INFO - iteration 312, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:21] {1987} INFO -  at 172.5s,\testimator lgbm's best error=0.5337,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:21] {1793} INFO - iteration 313, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:22] {1987} INFO -  at 173.8s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:22] {1793} INFO - iteration 314, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:23] {1987} INFO -  at 174.8s,\testimator catboost's best error=0.5272,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:23] {1793} INFO - iteration 315, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:23] {1987} INFO -  at 175.2s,\testimator lgbm's best error=0.5337,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:23] {1793} INFO - iteration 316, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:24] {1987} INFO -  at 176.4s,\testimator lgbm's best error=0.5337,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:24] {1793} INFO - iteration 317, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:25] {1987} INFO -  at 176.6s,\testimator lgbm's best error=0.5337,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:25] {1793} INFO - iteration 318, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:25] {1987} INFO -  at 176.7s,\testimator lgbm's best error=0.5337,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:25] {1793} INFO - iteration 319, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:25] {1987} INFO -  at 176.8s,\testimator xgboost's best error=0.5292,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:25] {1793} INFO - iteration 320, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:27] {1987} INFO -  at 179.2s,\testimator lgbm's best error=0.5337,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:27] {1793} INFO - iteration 321, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:28] {1987} INFO -  at 179.7s,\testimator lgbm's best error=0.5337,\tbest estimator catboost's best error=0.5272\n",
            "[flaml.automl: 10-31 07:53:28] {2087} INFO - selected model: <catboost.core.CatBoostRegressor object at 0x7fead4cc1c10>\n",
            "[flaml.automl: 10-31 07:53:28] {1576} INFO - fit succeeded\n",
            "[flaml.automl: 10-31 07:53:28] {1578} INFO - Time taken to find the best model: 71.66848564147949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие гиперпараметры для TST: {'early_stopping_rounds': 33, 'learning_rate': 0.02502472461274365, 'n_estimators': 5669}\n",
            "Лучшая метрика для TST: 0.5272374091968312\n",
            "Время на обучение для TST: 2.821840524673462 s\n",
            "score для TST = 16.601835144382722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcAbTbb9Fb6p",
        "outputId": "ae2c86a8-30f0-4225-d5ef-bc383eb16ef8"
      },
      "source": [
        "automl_2 = AutoML()\n",
        "settings_2 = {\n",
        "    \"time_budget\": 180,\n",
        "    \"metric\": 'r2',\n",
        "    \"estimator_list\": ['lgbm', 'xgboost', 'catboost'],\n",
        "    \"task\": 'regression'}                           \n",
        "automl_2.fit(X_train=X_train_2, y_train=y_train_2, X_val=X_valid_2, y_val=y_valid_2, **settings_2)\n",
        "\n",
        "print('Лучшие гиперпараметры для C:', automl_2.best_config)\n",
        "print(f'Лучшая метрика для C: {automl_1.best_loss}')\n",
        "print(f'Время на обучение для C: {automl_2.best_config_train_time} s')\n",
        "\n",
        "automl_2.model\n",
        "y_pred_2 = automl_2.predict(X_valid_2)\n",
        "print('score для C', '=', (mean_absolute_error(np.exp(y_valid_2), np.exp(y_pred_2)))) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 10-31 07:53:28] {1463} INFO - Data split method: uniform\n",
            "[flaml.automl: 10-31 07:53:28] {1467} INFO - Evaluation method: holdout\n",
            "[flaml.automl: 10-31 07:53:28] {1515} INFO - Minimizing error metric: 1-r2\n",
            "[flaml.automl: 10-31 07:53:28] {1552} INFO - List of ML learners in AutoML Run: ['lgbm', 'xgboost', 'catboost']\n",
            "[flaml.automl: 10-31 07:53:28] {1793} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:28] {1911} INFO - Estimated sufficient time budget=274s. Estimated necessary time budget=0s.\n",
            "[flaml.automl: 10-31 07:53:28] {1987} INFO -  at 0.0s,\testimator lgbm's best error=0.8417,\tbest estimator lgbm's best error=0.8417\n",
            "[flaml.automl: 10-31 07:53:28] {1793} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:28] {1987} INFO -  at 0.1s,\testimator lgbm's best error=0.8417,\tbest estimator lgbm's best error=0.8417\n",
            "[flaml.automl: 10-31 07:53:28] {1793} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:28] {1987} INFO -  at 0.1s,\testimator lgbm's best error=0.6993,\tbest estimator lgbm's best error=0.6993\n",
            "[flaml.automl: 10-31 07:53:28] {1793} INFO - iteration 3, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:28] {1987} INFO -  at 0.1s,\testimator lgbm's best error=0.6457,\tbest estimator lgbm's best error=0.6457\n",
            "[flaml.automl: 10-31 07:53:28] {1793} INFO - iteration 4, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:28] {1987} INFO -  at 0.2s,\testimator xgboost's best error=16.0603,\tbest estimator lgbm's best error=0.6457\n",
            "[flaml.automl: 10-31 07:53:28] {1793} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:28] {1987} INFO -  at 0.2s,\testimator lgbm's best error=0.6457,\tbest estimator lgbm's best error=0.6457\n",
            "[flaml.automl: 10-31 07:53:28] {1793} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:28] {1987} INFO -  at 0.2s,\testimator lgbm's best error=0.6338,\tbest estimator lgbm's best error=0.6338\n",
            "[flaml.automl: 10-31 07:53:28] {1793} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:28] {1987} INFO -  at 0.3s,\testimator lgbm's best error=0.6338,\tbest estimator lgbm's best error=0.6338\n",
            "[flaml.automl: 10-31 07:53:28] {1793} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:28] {1987} INFO -  at 0.3s,\testimator lgbm's best error=0.6338,\tbest estimator lgbm's best error=0.6338\n",
            "[flaml.automl: 10-31 07:53:28] {1793} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:28] {1987} INFO -  at 0.3s,\testimator lgbm's best error=0.5483,\tbest estimator lgbm's best error=0.5483\n",
            "[flaml.automl: 10-31 07:53:28] {1793} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:28] {1987} INFO -  at 0.4s,\testimator xgboost's best error=16.0603,\tbest estimator lgbm's best error=0.5483\n",
            "[flaml.automl: 10-31 07:53:28] {1793} INFO - iteration 11, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:28] {1987} INFO -  at 0.4s,\testimator xgboost's best error=3.9878,\tbest estimator lgbm's best error=0.5483\n",
            "[flaml.automl: 10-31 07:53:28] {1793} INFO - iteration 12, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:28] {1987} INFO -  at 0.4s,\testimator xgboost's best error=0.7284,\tbest estimator lgbm's best error=0.5483\n",
            "[flaml.automl: 10-31 07:53:28] {1793} INFO - iteration 13, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:28] {1987} INFO -  at 0.4s,\testimator xgboost's best error=0.7284,\tbest estimator lgbm's best error=0.5483\n",
            "[flaml.automl: 10-31 07:53:28] {1793} INFO - iteration 14, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:28] {1987} INFO -  at 0.4s,\testimator xgboost's best error=0.7284,\tbest estimator lgbm's best error=0.5483\n",
            "[flaml.automl: 10-31 07:53:28] {1793} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:28] {1987} INFO -  at 0.5s,\testimator xgboost's best error=0.6501,\tbest estimator lgbm's best error=0.5483\n",
            "[flaml.automl: 10-31 07:53:28] {1793} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:28] {1987} INFO -  at 0.5s,\testimator lgbm's best error=0.5483,\tbest estimator lgbm's best error=0.5483\n",
            "[flaml.automl: 10-31 07:53:28] {1793} INFO - iteration 17, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:28] {1987} INFO -  at 0.5s,\testimator xgboost's best error=0.6353,\tbest estimator lgbm's best error=0.5483\n",
            "[flaml.automl: 10-31 07:53:28] {1793} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:28] {1987} INFO -  at 0.6s,\testimator lgbm's best error=0.5242,\tbest estimator lgbm's best error=0.5242\n",
            "[flaml.automl: 10-31 07:53:28] {1793} INFO - iteration 19, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:28] {1987} INFO -  at 0.7s,\testimator lgbm's best error=0.5242,\tbest estimator lgbm's best error=0.5242\n",
            "[flaml.automl: 10-31 07:53:28] {1793} INFO - iteration 20, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:29] {1987} INFO -  at 0.8s,\testimator lgbm's best error=0.5242,\tbest estimator lgbm's best error=0.5242\n",
            "[flaml.automl: 10-31 07:53:29] {1793} INFO - iteration 21, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:29] {1987} INFO -  at 0.9s,\testimator lgbm's best error=0.5242,\tbest estimator lgbm's best error=0.5242\n",
            "[flaml.automl: 10-31 07:53:29] {1793} INFO - iteration 22, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:29] {1987} INFO -  at 0.9s,\testimator xgboost's best error=0.5678,\tbest estimator lgbm's best error=0.5242\n",
            "[flaml.automl: 10-31 07:53:29] {1793} INFO - iteration 23, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:29] {1987} INFO -  at 0.9s,\testimator xgboost's best error=0.5532,\tbest estimator lgbm's best error=0.5242\n",
            "[flaml.automl: 10-31 07:53:29] {1793} INFO - iteration 24, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:29] {1987} INFO -  at 1.0s,\testimator lgbm's best error=0.5242,\tbest estimator lgbm's best error=0.5242\n",
            "[flaml.automl: 10-31 07:53:29] {1793} INFO - iteration 25, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:29] {1987} INFO -  at 1.1s,\testimator xgboost's best error=0.5532,\tbest estimator lgbm's best error=0.5242\n",
            "[flaml.automl: 10-31 07:53:29] {1793} INFO - iteration 26, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:29] {1987} INFO -  at 1.1s,\testimator xgboost's best error=0.5532,\tbest estimator lgbm's best error=0.5242\n",
            "[flaml.automl: 10-31 07:53:29] {1793} INFO - iteration 27, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:29] {1987} INFO -  at 1.1s,\testimator xgboost's best error=0.5532,\tbest estimator lgbm's best error=0.5242\n",
            "[flaml.automl: 10-31 07:53:29] {1793} INFO - iteration 28, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:29] {1987} INFO -  at 1.3s,\testimator lgbm's best error=0.5242,\tbest estimator lgbm's best error=0.5242\n",
            "[flaml.automl: 10-31 07:53:29] {1793} INFO - iteration 29, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:29] {1987} INFO -  at 1.3s,\testimator lgbm's best error=0.5242,\tbest estimator lgbm's best error=0.5242\n",
            "[flaml.automl: 10-31 07:53:29] {1793} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:29] {1987} INFO -  at 1.5s,\testimator lgbm's best error=0.5149,\tbest estimator lgbm's best error=0.5149\n",
            "[flaml.automl: 10-31 07:53:29] {1793} INFO - iteration 31, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:30] {1987} INFO -  at 2.3s,\testimator catboost's best error=0.4851,\tbest estimator catboost's best error=0.4851\n",
            "[flaml.automl: 10-31 07:53:30] {1793} INFO - iteration 32, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:31] {1987} INFO -  at 3.0s,\testimator catboost's best error=0.4758,\tbest estimator catboost's best error=0.4758\n",
            "[flaml.automl: 10-31 07:53:31] {1793} INFO - iteration 33, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:31] {1987} INFO -  at 3.1s,\testimator xgboost's best error=0.5532,\tbest estimator catboost's best error=0.4758\n",
            "[flaml.automl: 10-31 07:53:31] {1793} INFO - iteration 34, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:31] {1987} INFO -  at 3.7s,\testimator catboost's best error=0.4758,\tbest estimator catboost's best error=0.4758\n",
            "[flaml.automl: 10-31 07:53:31] {1793} INFO - iteration 35, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:33] {1987} INFO -  at 5.3s,\testimator catboost's best error=0.4664,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:33] {1793} INFO - iteration 36, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:33] {1987} INFO -  at 5.3s,\testimator xgboost's best error=0.5532,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:33] {1793} INFO - iteration 37, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:34] {1987} INFO -  at 6.0s,\testimator catboost's best error=0.4664,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:34] {1793} INFO - iteration 38, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:34] {1987} INFO -  at 6.1s,\testimator xgboost's best error=0.5532,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:34] {1793} INFO - iteration 39, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:36] {1987} INFO -  at 8.0s,\testimator catboost's best error=0.4664,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:36] {1793} INFO - iteration 40, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:37] {1987} INFO -  at 8.9s,\testimator catboost's best error=0.4664,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:37] {1793} INFO - iteration 41, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:37] {1987} INFO -  at 9.0s,\testimator lgbm's best error=0.5149,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:37] {1793} INFO - iteration 42, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:38] {1987} INFO -  at 10.0s,\testimator catboost's best error=0.4664,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:38] {1793} INFO - iteration 43, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:39] {1987} INFO -  at 11.1s,\testimator catboost's best error=0.4664,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:39] {1793} INFO - iteration 44, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:39] {1987} INFO -  at 11.2s,\testimator xgboost's best error=0.5532,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:39] {1793} INFO - iteration 45, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:39] {1987} INFO -  at 11.2s,\testimator xgboost's best error=0.5532,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:39] {1793} INFO - iteration 46, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:40] {1987} INFO -  at 12.5s,\testimator catboost's best error=0.4664,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:40] {1793} INFO - iteration 47, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:40] {1987} INFO -  at 12.7s,\testimator lgbm's best error=0.5149,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:40] {1793} INFO - iteration 48, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:40] {1987} INFO -  at 12.7s,\testimator xgboost's best error=0.5532,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:40] {1793} INFO - iteration 49, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:41] {1987} INFO -  at 13.5s,\testimator catboost's best error=0.4664,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:41] {1793} INFO - iteration 50, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:41] {1987} INFO -  at 13.5s,\testimator xgboost's best error=0.5532,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:41] {1793} INFO - iteration 51, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:41] {1987} INFO -  at 13.6s,\testimator xgboost's best error=0.5532,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:41] {1793} INFO - iteration 52, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:42] {1987} INFO -  at 14.0s,\testimator lgbm's best error=0.5149,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:42] {1793} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:42] {1987} INFO -  at 14.2s,\testimator lgbm's best error=0.5084,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:42] {1793} INFO - iteration 54, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:42] {1987} INFO -  at 14.2s,\testimator xgboost's best error=0.5532,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:42] {1793} INFO - iteration 55, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:42] {1987} INFO -  at 14.4s,\testimator lgbm's best error=0.5084,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:42] {1793} INFO - iteration 56, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:42] {1987} INFO -  at 14.4s,\testimator xgboost's best error=0.5532,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:42] {1793} INFO - iteration 57, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:42] {1987} INFO -  at 14.4s,\testimator xgboost's best error=0.5532,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:42] {1793} INFO - iteration 58, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:42] {1987} INFO -  at 14.6s,\testimator lgbm's best error=0.5084,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:42] {1793} INFO - iteration 59, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:42] {1987} INFO -  at 14.6s,\testimator xgboost's best error=0.5532,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:42] {1793} INFO - iteration 60, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:43] {1987} INFO -  at 14.9s,\testimator lgbm's best error=0.5084,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:43] {1793} INFO - iteration 61, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:43] {1987} INFO -  at 14.9s,\testimator xgboost's best error=0.5532,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:43] {1793} INFO - iteration 62, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:44] {1987} INFO -  at 15.8s,\testimator catboost's best error=0.4664,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:44] {1793} INFO - iteration 63, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:44] {1987} INFO -  at 16.2s,\testimator lgbm's best error=0.5084,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:44] {1793} INFO - iteration 64, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:44] {1987} INFO -  at 16.2s,\testimator xgboost's best error=0.5498,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:44] {1793} INFO - iteration 65, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:46] {1987} INFO -  at 18.2s,\testimator catboost's best error=0.4664,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:46] {1793} INFO - iteration 66, current learner xgboost\n",
            "[flaml.automl: 10-31 07:53:46] {1987} INFO -  at 18.3s,\testimator xgboost's best error=0.5498,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:46] {1793} INFO - iteration 67, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:46] {1987} INFO -  at 18.4s,\testimator lgbm's best error=0.5084,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:46] {1793} INFO - iteration 68, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:48] {1987} INFO -  at 19.8s,\testimator catboost's best error=0.4664,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:48] {1793} INFO - iteration 69, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:49] {1987} INFO -  at 20.8s,\testimator catboost's best error=0.4664,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:49] {1793} INFO - iteration 70, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:50] {1987} INFO -  at 22.6s,\testimator catboost's best error=0.4664,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:50] {1793} INFO - iteration 71, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:52] {1987} INFO -  at 24.1s,\testimator catboost's best error=0.4664,\tbest estimator catboost's best error=0.4664\n",
            "[flaml.automl: 10-31 07:53:52] {1793} INFO - iteration 72, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:53] {1987} INFO -  at 25.7s,\testimator catboost's best error=0.4597,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:53:53] {1793} INFO - iteration 73, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:54] {1987} INFO -  at 26.1s,\testimator catboost's best error=0.4597,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:53:54] {1793} INFO - iteration 74, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:54] {1987} INFO -  at 26.4s,\testimator lgbm's best error=0.5084,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:53:54] {1793} INFO - iteration 75, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:54] {1987} INFO -  at 26.5s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:53:54] {1793} INFO - iteration 76, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:56] {1987} INFO -  at 27.8s,\testimator catboost's best error=0.4597,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:53:56] {1793} INFO - iteration 77, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:56] {1987} INFO -  at 27.9s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:53:56] {1793} INFO - iteration 78, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:56] {1987} INFO -  at 28.1s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:53:56] {1793} INFO - iteration 79, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:57] {1987} INFO -  at 29.1s,\testimator catboost's best error=0.4597,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:53:57] {1793} INFO - iteration 80, current learner lgbm\n",
            "[flaml.automl: 10-31 07:53:57] {1987} INFO -  at 29.2s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:53:57] {1793} INFO - iteration 81, current learner catboost\n",
            "[flaml.automl: 10-31 07:53:58] {1987} INFO -  at 30.5s,\testimator catboost's best error=0.4597,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:53:58] {1793} INFO - iteration 82, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:00] {1987} INFO -  at 32.1s,\testimator catboost's best error=0.4597,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:54:00] {1793} INFO - iteration 83, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:01] {1987} INFO -  at 32.8s,\testimator catboost's best error=0.4597,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:54:01] {1793} INFO - iteration 84, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:01] {1987} INFO -  at 32.9s,\testimator xgboost's best error=0.5498,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:54:01] {1793} INFO - iteration 85, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:02] {1987} INFO -  at 34.0s,\testimator catboost's best error=0.4597,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:54:02] {1793} INFO - iteration 86, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:02] {1987} INFO -  at 34.1s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:54:02] {1793} INFO - iteration 87, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:02] {1987} INFO -  at 34.3s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:54:02] {1793} INFO - iteration 88, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:03] {1987} INFO -  at 35.5s,\testimator catboost's best error=0.4597,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:54:03] {1793} INFO - iteration 89, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:03] {1987} INFO -  at 35.5s,\testimator xgboost's best error=0.5498,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:54:03] {1793} INFO - iteration 90, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:04] {1987} INFO -  at 36.6s,\testimator catboost's best error=0.4597,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:54:04] {1793} INFO - iteration 91, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:05] {1987} INFO -  at 37.2s,\testimator catboost's best error=0.4597,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:54:05] {1793} INFO - iteration 92, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:06] {1987} INFO -  at 38.0s,\testimator catboost's best error=0.4597,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:54:06] {1793} INFO - iteration 93, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:06] {1987} INFO -  at 38.0s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:54:06] {1793} INFO - iteration 94, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:08] {1987} INFO -  at 39.8s,\testimator catboost's best error=0.4597,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:54:08] {1793} INFO - iteration 95, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:08] {1987} INFO -  at 40.0s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:54:08] {1793} INFO - iteration 96, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:08] {1987} INFO -  at 40.0s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:54:08] {1793} INFO - iteration 97, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:08] {1987} INFO -  at 40.2s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:54:08] {1793} INFO - iteration 98, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:08] {1987} INFO -  at 40.3s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4597\n",
            "[flaml.automl: 10-31 07:54:08] {1793} INFO - iteration 99, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:09] {1987} INFO -  at 41.5s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:09] {1793} INFO - iteration 100, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:09] {1987} INFO -  at 41.7s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:09] {1793} INFO - iteration 101, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:10] {1987} INFO -  at 41.9s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:10] {1793} INFO - iteration 102, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:10] {1987} INFO -  at 42.2s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:10] {1793} INFO - iteration 103, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:10] {1987} INFO -  at 42.3s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:10] {1793} INFO - iteration 104, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:10] {1987} INFO -  at 42.5s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:10] {1793} INFO - iteration 105, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:12] {1987} INFO -  at 44.0s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:12] {1793} INFO - iteration 106, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:12] {1987} INFO -  at 44.1s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:12] {1793} INFO - iteration 107, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:12] {1987} INFO -  at 44.8s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:12] {1793} INFO - iteration 108, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:13] {1987} INFO -  at 45.0s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:13] {1793} INFO - iteration 109, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:13] {1987} INFO -  at 45.0s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:13] {1793} INFO - iteration 110, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:14] {1987} INFO -  at 46.2s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:14] {1793} INFO - iteration 111, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:14] {1987} INFO -  at 46.2s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:14] {1793} INFO - iteration 112, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:15] {1987} INFO -  at 47.5s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:15] {1793} INFO - iteration 113, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:15] {1987} INFO -  at 47.6s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:15] {1793} INFO - iteration 114, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:15] {1987} INFO -  at 47.7s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:15] {1793} INFO - iteration 115, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:16] {1987} INFO -  at 48.5s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:16] {1793} INFO - iteration 116, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:18] {1987} INFO -  at 50.1s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:18] {1793} INFO - iteration 117, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:18] {1987} INFO -  at 50.5s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:18] {1793} INFO - iteration 118, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:19] {1987} INFO -  at 51.5s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:19] {1793} INFO - iteration 119, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:20] {1987} INFO -  at 52.5s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:20] {1793} INFO - iteration 120, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:21] {1987} INFO -  at 53.4s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:21] {1793} INFO - iteration 121, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:22] {1987} INFO -  at 54.5s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:22] {1793} INFO - iteration 122, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:22] {1987} INFO -  at 54.6s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:22] {1793} INFO - iteration 123, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:22] {1987} INFO -  at 54.6s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:22] {1793} INFO - iteration 124, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:23] {1987} INFO -  at 54.9s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:23] {1793} INFO - iteration 125, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:23] {1987} INFO -  at 55.0s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:23] {1793} INFO - iteration 126, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:23] {1987} INFO -  at 55.1s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:23] {1793} INFO - iteration 127, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:24] {1987} INFO -  at 56.4s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:24] {1793} INFO - iteration 128, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:24] {1987} INFO -  at 56.6s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:24] {1793} INFO - iteration 129, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:24] {1987} INFO -  at 56.7s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:24] {1793} INFO - iteration 130, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:26] {1987} INFO -  at 58.0s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:26] {1793} INFO - iteration 131, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:26] {1987} INFO -  at 58.1s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:26] {1793} INFO - iteration 132, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:26] {1987} INFO -  at 58.3s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:26] {1793} INFO - iteration 133, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:26] {1987} INFO -  at 58.4s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:26] {1793} INFO - iteration 134, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:28] {1987} INFO -  at 60.3s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:28] {1793} INFO - iteration 135, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:28] {1987} INFO -  at 60.4s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:28] {1793} INFO - iteration 136, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:28] {1987} INFO -  at 60.5s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:28] {1793} INFO - iteration 137, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:29] {1987} INFO -  at 61.3s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:29] {1793} INFO - iteration 138, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:29] {1987} INFO -  at 61.4s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:29] {1793} INFO - iteration 139, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:30] {1987} INFO -  at 62.5s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:30] {1793} INFO - iteration 140, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:30] {1987} INFO -  at 62.6s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:30] {1793} INFO - iteration 141, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:31] {1987} INFO -  at 63.5s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:31] {1793} INFO - iteration 142, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:32] {1987} INFO -  at 64.7s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:32] {1793} INFO - iteration 143, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:33] {1987} INFO -  at 64.9s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:33] {1793} INFO - iteration 144, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:33] {1987} INFO -  at 65.2s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:33] {1793} INFO - iteration 145, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:33] {1987} INFO -  at 65.2s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:33] {1793} INFO - iteration 146, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:33] {1987} INFO -  at 65.5s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:33] {1793} INFO - iteration 147, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:33] {1987} INFO -  at 65.6s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:33] {1793} INFO - iteration 148, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:34] {1987} INFO -  at 66.0s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:34] {1793} INFO - iteration 149, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:34] {1987} INFO -  at 66.0s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:34] {1793} INFO - iteration 150, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:35] {1987} INFO -  at 67.1s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:35] {1793} INFO - iteration 151, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:35] {1987} INFO -  at 67.3s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:35] {1793} INFO - iteration 152, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:35] {1987} INFO -  at 67.5s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:35] {1793} INFO - iteration 153, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:35] {1987} INFO -  at 67.6s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:35] {1793} INFO - iteration 154, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:36] {1987} INFO -  at 68.2s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:36] {1793} INFO - iteration 155, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:36] {1987} INFO -  at 68.3s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:36] {1793} INFO - iteration 156, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:36] {1987} INFO -  at 68.5s,\testimator xgboost's best error=0.5237,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:36] {1793} INFO - iteration 157, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:36] {1987} INFO -  at 68.6s,\testimator xgboost's best error=0.4975,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:36] {1793} INFO - iteration 158, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:37] {1987} INFO -  at 69.6s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:37] {1793} INFO - iteration 159, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:38] {1987} INFO -  at 69.9s,\testimator xgboost's best error=0.4975,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:38] {1793} INFO - iteration 160, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:38] {1987} INFO -  at 69.9s,\testimator xgboost's best error=0.4975,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:38] {1793} INFO - iteration 161, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:39] {1987} INFO -  at 70.8s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:39] {1793} INFO - iteration 162, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:40] {1987} INFO -  at 72.2s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:40] {1793} INFO - iteration 163, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:41] {1987} INFO -  at 72.9s,\testimator xgboost's best error=0.4975,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:41] {1793} INFO - iteration 164, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:41] {1987} INFO -  at 72.9s,\testimator xgboost's best error=0.4975,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:41] {1793} INFO - iteration 165, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:41] {1987} INFO -  at 73.0s,\testimator xgboost's best error=0.4975,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:41] {1793} INFO - iteration 166, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:42] {1987} INFO -  at 73.8s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:42] {1793} INFO - iteration 167, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:42] {1987} INFO -  at 74.1s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:42] {1793} INFO - iteration 168, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:42] {1987} INFO -  at 74.2s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:42] {1793} INFO - iteration 169, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:42] {1987} INFO -  at 74.2s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:42] {1793} INFO - iteration 170, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:42] {1987} INFO -  at 74.4s,\testimator xgboost's best error=0.4975,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:42] {1793} INFO - iteration 171, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:42] {1987} INFO -  at 74.5s,\testimator xgboost's best error=0.4975,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:42] {1793} INFO - iteration 172, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:42] {1987} INFO -  at 74.7s,\testimator xgboost's best error=0.4975,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:42] {1793} INFO - iteration 173, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:43] {1987} INFO -  at 74.9s,\testimator xgboost's best error=0.4975,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:43] {1793} INFO - iteration 174, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:44] {1987} INFO -  at 76.3s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:44] {1793} INFO - iteration 175, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:44] {1987} INFO -  at 76.4s,\testimator xgboost's best error=0.4975,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:44] {1793} INFO - iteration 176, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:44] {1987} INFO -  at 76.5s,\testimator xgboost's best error=0.4975,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:44] {1793} INFO - iteration 177, current learner xgboost\n",
            "[flaml.automl: 10-31 07:54:45] {1987} INFO -  at 76.9s,\testimator xgboost's best error=0.4973,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:45] {1793} INFO - iteration 178, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:46] {1987} INFO -  at 77.8s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:46] {1793} INFO - iteration 179, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:47] {1987} INFO -  at 79.0s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:47] {1793} INFO - iteration 180, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:47] {1987} INFO -  at 79.2s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:47] {1793} INFO - iteration 181, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:47] {1987} INFO -  at 79.3s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:47] {1793} INFO - iteration 182, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:48] {1987} INFO -  at 80.0s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:48] {1793} INFO - iteration 183, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:49] {1987} INFO -  at 81.2s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:49] {1793} INFO - iteration 184, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:49] {1987} INFO -  at 81.3s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:49] {1793} INFO - iteration 185, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:50] {1987} INFO -  at 82.2s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:50] {1793} INFO - iteration 186, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:50] {1987} INFO -  at 82.3s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:50] {1793} INFO - iteration 187, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:50] {1987} INFO -  at 82.6s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:50] {1793} INFO - iteration 188, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:52] {1987} INFO -  at 83.9s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:52] {1793} INFO - iteration 189, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:52] {1987} INFO -  at 84.1s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:52] {1793} INFO - iteration 190, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:53] {1987} INFO -  at 85.4s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:53] {1793} INFO - iteration 191, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:54] {1987} INFO -  at 86.6s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:54] {1793} INFO - iteration 192, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:55] {1987} INFO -  at 87.7s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:55] {1793} INFO - iteration 193, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:55] {1987} INFO -  at 87.7s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:55] {1793} INFO - iteration 194, current learner lgbm\n",
            "[flaml.automl: 10-31 07:54:56] {1987} INFO -  at 87.9s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:56] {1793} INFO - iteration 195, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:57] {1987} INFO -  at 89.3s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:57] {1793} INFO - iteration 196, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:58] {1987} INFO -  at 90.7s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:58] {1793} INFO - iteration 197, current learner catboost\n",
            "[flaml.automl: 10-31 07:54:59] {1987} INFO -  at 91.7s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:54:59] {1793} INFO - iteration 198, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:01] {1987} INFO -  at 92.8s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:01] {1793} INFO - iteration 199, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:01] {1987} INFO -  at 92.9s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:01] {1793} INFO - iteration 200, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:01] {1987} INFO -  at 93.0s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:01] {1793} INFO - iteration 201, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:02] {1987} INFO -  at 94.0s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:02] {1793} INFO - iteration 202, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:03] {1987} INFO -  at 95.0s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:03] {1793} INFO - iteration 203, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:05] {1987} INFO -  at 97.1s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:05] {1793} INFO - iteration 204, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:06] {1987} INFO -  at 98.1s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:06] {1793} INFO - iteration 205, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:07] {1987} INFO -  at 99.2s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:07] {1793} INFO - iteration 206, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:08] {1987} INFO -  at 100.1s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:08] {1793} INFO - iteration 207, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:08] {1987} INFO -  at 100.3s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:08] {1793} INFO - iteration 208, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:10] {1987} INFO -  at 101.9s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:10] {1793} INFO - iteration 209, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:11] {1987} INFO -  at 102.9s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:11] {1793} INFO - iteration 210, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:12] {1987} INFO -  at 103.9s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:12] {1793} INFO - iteration 211, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:13] {1987} INFO -  at 105.3s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:13] {1793} INFO - iteration 212, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:14] {1987} INFO -  at 106.5s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:14] {1793} INFO - iteration 213, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:14] {1987} INFO -  at 106.6s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:14] {1793} INFO - iteration 214, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:16] {1987} INFO -  at 107.9s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:16] {1793} INFO - iteration 215, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:16] {1987} INFO -  at 108.1s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:16] {1793} INFO - iteration 216, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:16] {1987} INFO -  at 108.3s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:16] {1793} INFO - iteration 217, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:16] {1987} INFO -  at 108.4s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:16] {1793} INFO - iteration 218, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:17] {1987} INFO -  at 109.2s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:17] {1793} INFO - iteration 219, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:17] {1987} INFO -  at 109.4s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:17] {1793} INFO - iteration 220, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:18] {1987} INFO -  at 110.1s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:18] {1793} INFO - iteration 221, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:19] {1987} INFO -  at 111.1s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:19] {1793} INFO - iteration 222, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:19] {1987} INFO -  at 111.2s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:19] {1793} INFO - iteration 223, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:19] {1987} INFO -  at 111.2s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:19] {1793} INFO - iteration 224, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:19] {1987} INFO -  at 111.6s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:19] {1793} INFO - iteration 225, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:20] {1987} INFO -  at 111.8s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:20] {1793} INFO - iteration 226, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:20] {1987} INFO -  at 112.8s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:20] {1793} INFO - iteration 227, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:21] {1987} INFO -  at 112.8s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:21] {1793} INFO - iteration 228, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:22] {1987} INFO -  at 114.2s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:22] {1793} INFO - iteration 229, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:23] {1987} INFO -  at 115.6s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:23] {1793} INFO - iteration 230, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:24] {1987} INFO -  at 116.6s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:24] {1793} INFO - iteration 231, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:25] {1987} INFO -  at 117.7s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:25] {1793} INFO - iteration 232, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:27] {1987} INFO -  at 118.9s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:27] {1793} INFO - iteration 233, current learner xgboost\n",
            "[flaml.automl: 10-31 07:55:27] {1987} INFO -  at 119.2s,\testimator xgboost's best error=0.4973,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:27] {1793} INFO - iteration 234, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:28] {1987} INFO -  at 120.2s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:28] {1793} INFO - iteration 235, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:29] {1987} INFO -  at 121.1s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:29] {1793} INFO - iteration 236, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:29] {1987} INFO -  at 121.2s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:29] {1793} INFO - iteration 237, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:30] {1987} INFO -  at 122.1s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:30] {1793} INFO - iteration 238, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:31] {1987} INFO -  at 123.6s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:31] {1793} INFO - iteration 239, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:32] {1987} INFO -  at 123.8s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:32] {1793} INFO - iteration 240, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:32] {1987} INFO -  at 124.6s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:32] {1793} INFO - iteration 241, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:33] {1987} INFO -  at 124.8s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:33] {1793} INFO - iteration 242, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:34] {1987} INFO -  at 125.9s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:34] {1793} INFO - iteration 243, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:34] {1987} INFO -  at 126.0s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:34] {1793} INFO - iteration 244, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:35] {1987} INFO -  at 126.9s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:35] {1793} INFO - iteration 245, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:36] {1987} INFO -  at 128.2s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:36] {1793} INFO - iteration 246, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:36] {1987} INFO -  at 128.5s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:36] {1793} INFO - iteration 247, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:37] {1987} INFO -  at 129.5s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:37] {1793} INFO - iteration 248, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:38] {1987} INFO -  at 130.4s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:38] {1793} INFO - iteration 249, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:38] {1987} INFO -  at 130.5s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:38] {1793} INFO - iteration 250, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:38] {1987} INFO -  at 130.6s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:38] {1793} INFO - iteration 251, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:40] {1987} INFO -  at 132.1s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:40] {1793} INFO - iteration 252, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:41] {1987} INFO -  at 133.2s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:41] {1793} INFO - iteration 253, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:41] {1987} INFO -  at 133.3s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:41] {1793} INFO - iteration 254, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:42] {1987} INFO -  at 134.3s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:42] {1793} INFO - iteration 255, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:42] {1987} INFO -  at 134.4s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:42] {1793} INFO - iteration 256, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:44] {1987} INFO -  at 135.9s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:44] {1793} INFO - iteration 257, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:45] {1987} INFO -  at 137.1s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:45] {1793} INFO - iteration 258, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:46] {1987} INFO -  at 138.2s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:46] {1793} INFO - iteration 259, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:47] {1987} INFO -  at 138.9s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:47] {1793} INFO - iteration 260, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:48] {1987} INFO -  at 140.0s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:48] {1793} INFO - iteration 261, current learner lgbm\n",
            "[flaml.automl: 10-31 07:55:48] {1987} INFO -  at 140.2s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:48] {1793} INFO - iteration 262, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:49] {1987} INFO -  at 141.4s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:49] {1793} INFO - iteration 263, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:51] {1987} INFO -  at 142.8s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:51] {1793} INFO - iteration 264, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:51] {1987} INFO -  at 143.8s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:51] {1793} INFO - iteration 265, current learner catboost\n",
            "[flaml.automl: 10-31 07:55:54] {1987} INFO -  at 146.6s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:55:54] {1793} INFO - iteration 266, current learner catboost\n",
            "[flaml.automl: 10-31 07:56:00] {1987} INFO -  at 151.9s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:00] {1793} INFO - iteration 267, current learner catboost\n",
            "[flaml.automl: 10-31 07:56:02] {1987} INFO -  at 154.7s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:02] {1793} INFO - iteration 268, current learner lgbm\n",
            "[flaml.automl: 10-31 07:56:03] {1987} INFO -  at 154.9s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:03] {1793} INFO - iteration 269, current learner catboost\n",
            "[flaml.automl: 10-31 07:56:07] {1987} INFO -  at 158.9s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:07] {1793} INFO - iteration 270, current learner lgbm\n",
            "[flaml.automl: 10-31 07:56:07] {1987} INFO -  at 159.0s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:07] {1793} INFO - iteration 271, current learner lgbm\n",
            "[flaml.automl: 10-31 07:56:07] {1987} INFO -  at 159.0s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:07] {1793} INFO - iteration 272, current learner lgbm\n",
            "[flaml.automl: 10-31 07:56:07] {1987} INFO -  at 159.2s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:07] {1793} INFO - iteration 273, current learner lgbm\n",
            "[flaml.automl: 10-31 07:56:07] {1987} INFO -  at 159.3s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:07] {1793} INFO - iteration 274, current learner lgbm\n",
            "[flaml.automl: 10-31 07:56:07] {1987} INFO -  at 159.4s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:07] {1793} INFO - iteration 275, current learner catboost\n",
            "[flaml.automl: 10-31 07:56:10] {1987} INFO -  at 162.8s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:10] {1793} INFO - iteration 276, current learner lgbm\n",
            "[flaml.automl: 10-31 07:56:11] {1987} INFO -  at 162.8s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:11] {1793} INFO - iteration 277, current learner catboost\n",
            "[flaml.automl: 10-31 07:56:13] {1987} INFO -  at 165.6s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:13] {1793} INFO - iteration 278, current learner catboost\n",
            "[flaml.automl: 10-31 07:56:16] {1987} INFO -  at 167.9s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:16] {1793} INFO - iteration 279, current learner lgbm\n",
            "[flaml.automl: 10-31 07:56:16] {1987} INFO -  at 168.1s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:16] {1793} INFO - iteration 280, current learner lgbm\n",
            "[flaml.automl: 10-31 07:56:16] {1987} INFO -  at 168.2s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:16] {1793} INFO - iteration 281, current learner lgbm\n",
            "[flaml.automl: 10-31 07:56:16] {1987} INFO -  at 168.3s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:16] {1793} INFO - iteration 282, current learner catboost\n",
            "[flaml.automl: 10-31 07:56:18] {1987} INFO -  at 170.2s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:18] {1793} INFO - iteration 283, current learner catboost\n",
            "[flaml.automl: 10-31 07:56:20] {1987} INFO -  at 171.8s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:20] {1793} INFO - iteration 284, current learner catboost\n",
            "[flaml.automl: 10-31 07:56:21] {1987} INFO -  at 173.2s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:21] {1793} INFO - iteration 285, current learner catboost\n",
            "[flaml.automl: 10-31 07:56:22] {1987} INFO -  at 174.4s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:22] {1793} INFO - iteration 286, current learner lgbm\n",
            "[flaml.automl: 10-31 07:56:22] {1987} INFO -  at 174.5s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:22] {1793} INFO - iteration 287, current learner lgbm\n",
            "[flaml.automl: 10-31 07:56:22] {1987} INFO -  at 174.6s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:22] {1793} INFO - iteration 288, current learner catboost\n",
            "[flaml.automl: 10-31 07:56:23] {1987} INFO -  at 175.5s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:23] {1793} INFO - iteration 289, current learner xgboost\n",
            "[flaml.automl: 10-31 07:56:24] {1987} INFO -  at 175.9s,\testimator xgboost's best error=0.4973,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:24] {1793} INFO - iteration 290, current learner catboost\n",
            "[flaml.automl: 10-31 07:56:24] {1987} INFO -  at 176.6s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:24] {1793} INFO - iteration 291, current learner catboost\n",
            "[flaml.automl: 10-31 07:56:25] {1987} INFO -  at 177.2s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:25] {1793} INFO - iteration 292, current learner catboost\n",
            "[flaml.automl: 10-31 07:56:25] {1987} INFO -  at 177.7s,\testimator catboost's best error=0.4580,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:25] {1793} INFO - iteration 293, current learner xgboost\n",
            "[flaml.automl: 10-31 07:56:27] {1987} INFO -  at 179.4s,\testimator xgboost's best error=0.4973,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:27] {1793} INFO - iteration 294, current learner lgbm\n",
            "[flaml.automl: 10-31 07:56:27] {1987} INFO -  at 179.5s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:27] {1793} INFO - iteration 295, current learner lgbm\n",
            "[flaml.automl: 10-31 07:56:27] {1987} INFO -  at 179.7s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:27] {1793} INFO - iteration 296, current learner lgbm\n",
            "[flaml.automl: 10-31 07:56:28] {1987} INFO -  at 179.8s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:28] {1793} INFO - iteration 297, current learner lgbm\n",
            "[flaml.automl: 10-31 07:56:28] {1987} INFO -  at 179.9s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:28] {1793} INFO - iteration 298, current learner lgbm\n",
            "[flaml.automl: 10-31 07:56:28] {1987} INFO -  at 180.0s,\testimator lgbm's best error=0.4996,\tbest estimator catboost's best error=0.4580\n",
            "[flaml.automl: 10-31 07:56:28] {2087} INFO - selected model: <catboost.core.CatBoostRegressor object at 0x7fead4b8c450>\n",
            "[flaml.automl: 10-31 07:56:28] {1576} INFO - fit succeeded\n",
            "[flaml.automl: 10-31 07:56:28] {1578} INFO - Time taken to find the best model: 41.52071142196655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие гиперпараметры для C: {'early_stopping_rounds': 16, 'learning_rate': 0.05860143758327679, 'n_estimators': 7283}\n",
            "Лучшая метрика для C: 0.5272374091968312\n",
            "Время на обучение для C: 1.2459328174591064 s\n",
            "score для C = 0.025178565318712116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U6L7EwcJW5v",
        "outputId": "1346407e-819d-47b7-a6d3-9161df2fed47"
      },
      "source": [
        "answer_df_train = pd.DataFrame({'TST':y_valid_1, 'C':y_valid_2})\n",
        "pred_df_train = pd.DataFrame({'TST':automl_1.predict(X_valid_1), 'C':np.exp(automl_2.predict(X_valid_2))})\n",
        "metr = metric(answer_df_train, pred_df_train)\n",
        "metr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3397058823529412"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58UJ0nvsTNqL"
      },
      "source": [
        "X_tr_TST = all_tables_train_number.drop('C',1)\n",
        "X_tr_C = all_tables_train_number.drop('TST',1)\n",
        "y_c = np.log(all_tables_train_number['C'])\n",
        "y_tst = all_tables_train_number['TST']\n",
        "standart = StandardScaler()\n",
        "X_tr_TST = standart.fit_transform(X_tr_TST)\n",
        "X_tr_C = standart.fit_transform(X_tr_C)\n",
        "X_train_tst, X_valid_tst, y_train_tst, y_valid_tst = train_test_split(X_tr_TST, y_tst, test_size=0.33, random_state=42)\n",
        "X_train_c, X_valid_c, y_train_c, y_valid_c = train_test_split(X_tr_C, y_c, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MOAKM98Th-b"
      },
      "source": [
        "automl_tst = AutoML()\n",
        "settings_tst = {\n",
        "    \"time_budget\": 180,\n",
        "    \"metric\": 'r2',\n",
        "    \"estimator_list\": ['lgbm', 'xgboost', 'catboost'],\n",
        "    \"task\": 'regression'}                           \n",
        "automl_tst.fit(X_train=X_train_tst, y_train=y_train_tst, X_val=X_valid_tst, y_val=y_valid_tst, **settings_tst)  \n",
        "\n",
        "print('Лучшие гиперпараметры для tst_new:', automl_tst.best_config)\n",
        "print(f'Лучшая метрика для tst_new: {automl_tst.best_loss}')\n",
        "print(f'Время на обучение для tst_new: {automl_tst.best_config_train_time} s')\n",
        "\n",
        "automl_tst.model\n",
        "y_pred_tst = automl_tst.predict(X_valid_tst)\n",
        "print('score для tst_new', '=', (mean_absolute_error(y_valid_tst, y_pred_tst))) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHBWWiYRUkA4"
      },
      "source": [
        "automl_c = AutoML()\n",
        "settings_c = {\n",
        "    \"time_budget\": 180,\n",
        "    \"metric\": 'r2',\n",
        "    \"estimator_list\": ['lgbm', 'xgboost', 'catboost'],\n",
        "    \"task\": 'regression'}                           \n",
        "automl_c.fit(X_train=X_train_c, y_train=y_train_c, X_val=X_valid_c, y_val=y_valid_c, **settings_c)  \n",
        "\n",
        "print('Лучшие гиперпараметры для C_new:', automl_c.best_config)\n",
        "print(f'Лучшая метрика для C_new: {automl_c.best_loss}')\n",
        "print(f'Время на обучение для C_new: {automl_c.best_config_train_time} s')\n",
        "\n",
        "automl_c.model\n",
        "y_pred_c = automl_c.predict(X_valid_c)\n",
        "print('score для C_new', '=', (mean_absolute_error(np.exp(y_valid_c), np.exp(y_pred_c)))) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNF5ir7-V9l4"
      },
      "source": [
        "c = automl_2.predict(X_ts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADlOzP86XLHZ",
        "outputId": "6570181d-7311-48dd-acf3-73e35584571b"
      },
      "source": [
        "all_tables_test_number_1 = all_tables_test_number\n",
        "all_tables_test_number_1['C'] = np.exp(c)\n",
        "# all_tables_test_number_1 = all_tables_test_number_1.drop('TST',1,inplace=True)\n",
        "X_ts_1 = all_tables_test_number_1\n",
        "X_ts_1 = standart.fit_transform(X_ts_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwnorSSPXZBM"
      },
      "source": [
        "tst = automl_tst.predict(X_ts_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv_zxiigOuq7"
      },
      "source": [
        "pred_df_test = pd.DataFrame({'NPLV': sample_submission.NPLV,'TST':automl_1.predict(X_ts), 'C':np.exp(automl_2.predict(X_ts))})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "moRlLwuAY5RC",
        "outputId": "c4fc2481-386b-4660-a91c-7be86f14bc03"
      },
      "source": [
        "pred_df_test_1 =  pd.DataFrame({'NPLV': sample_submission.NPLV,'TST':tst, 'C':np.exp(c)})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NPLV</th>\n",
              "      <th>TST</th>\n",
              "      <th>C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>512324</td>\n",
              "      <td>1621.093353</td>\n",
              "      <td>0.024012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>512327</td>\n",
              "      <td>1618.074985</td>\n",
              "      <td>0.016594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>512328</td>\n",
              "      <td>1680.393290</td>\n",
              "      <td>0.175834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>512331</td>\n",
              "      <td>1618.071704</td>\n",
              "      <td>0.016594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>512333</td>\n",
              "      <td>1655.970486</td>\n",
              "      <td>0.113656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>775</th>\n",
              "      <td>513369</td>\n",
              "      <td>1618.166600</td>\n",
              "      <td>0.016531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>776</th>\n",
              "      <td>513370</td>\n",
              "      <td>1618.160128</td>\n",
              "      <td>0.016595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>777</th>\n",
              "      <td>513371</td>\n",
              "      <td>1618.143030</td>\n",
              "      <td>0.016594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>778</th>\n",
              "      <td>513372</td>\n",
              "      <td>1618.103558</td>\n",
              "      <td>0.016599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>779</th>\n",
              "      <td>513374</td>\n",
              "      <td>1687.843709</td>\n",
              "      <td>0.195409</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>780 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       NPLV          TST         C\n",
              "0    512324  1621.093353  0.024012\n",
              "1    512327  1618.074985  0.016594\n",
              "2    512328  1680.393290  0.175834\n",
              "3    512331  1618.071704  0.016594\n",
              "4    512333  1655.970486  0.113656\n",
              "..      ...          ...       ...\n",
              "775  513369  1618.166600  0.016531\n",
              "776  513370  1618.160128  0.016595\n",
              "777  513371  1618.143030  0.016594\n",
              "778  513372  1618.103558  0.016599\n",
              "779  513374  1687.843709  0.195409\n",
              "\n",
              "[780 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 633
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "JALrH98_PJ6A",
        "outputId": "a3861db8-d672-47de-a86a-36d2fb5bf033"
      },
      "source": [
        "prediction = pred_df_test.to_csv('evraz_14.csv', index=False)\n",
        "predictions = pd.read_csv('/content/evraz_14.csv')\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NPLV</th>\n",
              "      <th>TST</th>\n",
              "      <th>C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>512324</td>\n",
              "      <td>1652.251220</td>\n",
              "      <td>0.037221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>512327</td>\n",
              "      <td>1648.007902</td>\n",
              "      <td>0.046454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>512328</td>\n",
              "      <td>1650.214619</td>\n",
              "      <td>0.060392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>512331</td>\n",
              "      <td>1641.590586</td>\n",
              "      <td>0.096554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>512333</td>\n",
              "      <td>1656.695045</td>\n",
              "      <td>0.082941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>775</th>\n",
              "      <td>513369</td>\n",
              "      <td>1640.332304</td>\n",
              "      <td>0.109469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>776</th>\n",
              "      <td>513370</td>\n",
              "      <td>1651.106519</td>\n",
              "      <td>0.125532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>777</th>\n",
              "      <td>513371</td>\n",
              "      <td>1655.041736</td>\n",
              "      <td>0.090544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>778</th>\n",
              "      <td>513372</td>\n",
              "      <td>1658.879778</td>\n",
              "      <td>0.072067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>779</th>\n",
              "      <td>513374</td>\n",
              "      <td>1657.499013</td>\n",
              "      <td>0.053443</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>780 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       NPLV          TST         C\n",
              "0    512324  1652.251220  0.037221\n",
              "1    512327  1648.007902  0.046454\n",
              "2    512328  1650.214619  0.060392\n",
              "3    512331  1641.590586  0.096554\n",
              "4    512333  1656.695045  0.082941\n",
              "..      ...          ...       ...\n",
              "775  513369  1640.332304  0.109469\n",
              "776  513370  1651.106519  0.125532\n",
              "777  513371  1655.041736  0.090544\n",
              "778  513372  1658.879778  0.072067\n",
              "779  513374  1657.499013  0.053443\n",
              "\n",
              "[780 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    }
  ]
}